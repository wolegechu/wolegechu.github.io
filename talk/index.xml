<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Recent &amp; Upcoming Talks on Yuchu Luo - 罗宇矗</title>
    <link>/talk/</link>
    <description>Recent content in Recent &amp; Upcoming Talks on Yuchu Luo - 罗宇矗</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Yuchu Luo</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/talk/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>End-to-end Deep Models For Self-driving Car (Avaliable soon)</title>
      <link>/talk/end-to-end-deep-models-for-self-driving-car/</link>
      <pubDate>Sun, 26 Nov 2017 19:00:00 +0000</pubDate>
      
      <guid>/talk/end-to-end-deep-models-for-self-driving-car/</guid>
      <description>

&lt;hr /&gt;

&lt;h2 id=&#34;reference&#34;&gt;Reference:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Huval, Brody, et al. &amp;ldquo;An empirical evaluation of deep learning on highway driving.&amp;ldquo; arXiv preprint arXiv:1504.01716 (2015).&lt;/li&gt;
&lt;li&gt;Ulbrich, Simon, et al. &amp;ldquo;Towards a Functional System Architecture for Automated Vehicles.&amp;ldquo; arXiv preprint arXiv:1703.08557 (2017).&lt;/li&gt;
&lt;li&gt;Pomerleau, Dean A. &amp;ldquo;Alvinn: An autonomous land vehicle in a neural network.&amp;ldquo; 
Advances in neural information processing systems. 1989.&lt;/li&gt;
&lt;li&gt;Muller, Urs, et al. &amp;ldquo;Off-road obstacle avoidance through end-to-end learning.“ Advances in neural information processing systems. 2006.APA&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Chen, Chenyi, et al. &amp;ldquo;Deepdriving: Learning affordance for direct perception in autonomous driving.&amp;ldquo; Proceedings of the IEEE International Conference on Computer Vision. 2015.&lt;/li&gt;
&lt;li&gt;Chen, Chenyi, et al. &amp;ldquo;Deepdriving: Learning affordance for direct perception in autonomous driving.&amp;ldquo; Proceedings of the IEEE International Conference on Computer Vision. 2015.&lt;/li&gt;
&lt;li&gt;Bojarski, Mariusz, et al. &amp;ldquo;End to end learning for self-driving cars.&amp;ldquo; arXiv preprint arXiv:1604.07316 (2016).&lt;/li&gt;
&lt;li&gt;Codevilla, Felipe, et al. &amp;ldquo;End-to-end driving via conditional imitation learning.&amp;ldquo; arXiv preprint arXiv:1710.02410 (2017).&lt;/li&gt;
&lt;li&gt;Xu, Huazhe, et al. &amp;ldquo;End-to-end learning of driving models from large-scale video datasets.&amp;ldquo; arXiv preprint arXiv:1612.01079(2016).&lt;/li&gt;
&lt;li&gt;Mukadam, Mustafa, et al. “Tactical Decision Making for Lane Changing with Deep Reinforcement Learning.&amp;rdquo; (2017).&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>卷积神经网络：从相遇相知到相爱</title>
      <link>/talk/cnn/</link>
      <pubDate>Fri, 10 Nov 2017 19:00:00 +0000</pubDate>
      
      <guid>/talk/cnn/</guid>
      <description>&lt;hr /&gt;

&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;7aba17f26f474cb9aebb0ffba3c11446&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>如何实现无人驾驶</title>
      <link>/talk/how-to-build-self-driving-car/</link>
      <pubDate>Fri, 20 Oct 2017 19:00:00 +0000</pubDate>
      
      <guid>/talk/how-to-build-self-driving-car/</guid>
      <description>&lt;p&gt;MIL 智能体组无人驾驶汽车项目介绍&lt;/p&gt;

&lt;hr /&gt;
</description>
    </item>
    
    <item>
      <title>Deep Reinforcement Learning</title>
      <link>/talk/deep-reinforcemnt-learning/</link>
      <pubDate>Mon, 28 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/talk/deep-reinforcemnt-learning/</guid>
      <description>&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;62b49c13db9b4b61a97bc64140d96453&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;Markov Decision Processes&lt;/li&gt;
&lt;li&gt;Policy Learning and Value Learning&lt;/li&gt;
&lt;li&gt;Bellman Equation&lt;/li&gt;
&lt;li&gt;Model-based and Model-free&lt;/li&gt;
&lt;li&gt;Q-learning, Policy Gradients, Actor-Critic&lt;/li&gt;
&lt;li&gt;Experience Replay&lt;/li&gt;
&lt;li&gt;Applications: Atari Game, Recurrent Attention Model(RAM)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Referfence and Recommend Materials&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CS231n: Deep Reinforcement Learning (&lt;a href=&#34;https://www.youtube.com/watch?v=lvoHnicueoE&amp;amp;index=14&amp;amp;list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&#34; target=&#34;_blank&#34;&gt;Video&lt;/a&gt;) (&lt;a href=&#34;http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture14.pdf&#34; target=&#34;_blank&#34;&gt;Slide&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1312.5602&#34; target=&#34;_blank&#34;&gt;Playing Atari with Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1406.6247&#34; target=&#34;_blank&#34;&gt;Recurrent Models of Visual Attention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow&#34; target=&#34;_blank&#34;&gt;Reinforcement Learning Methods and Tutorials&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Intro to Reinforcement Learning</title>
      <link>/talk/reinforcement-learning/</link>
      <pubDate>Wed, 23 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/talk/reinforcement-learning/</guid>
      <description>&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;2b0ad1af004f4266b693269e394f35cf&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;Markov Decision Processes&lt;/li&gt;
&lt;li&gt;Model-based and Model-free&lt;/li&gt;
&lt;li&gt;Value Iteration and Policy Iteration&lt;/li&gt;
&lt;li&gt;Q-learning and approximate Q-learning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Referfence and Recommend Materials&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25319023&#34; target=&#34;_blank&#34;&gt;强化学习（Reinforcement Learning）知识整理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;UC Berkeley CS188 Intro to AI&#34; target=&#34;_blank&#34;&gt;UC Berkeley CS188 Intro to AI&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Markov Decision Processe

&lt;ul&gt;
&lt;li&gt;(&lt;a href=&#34;http://www.youtube.com/watch?v=Oxqwwnm_x0s&#34; target=&#34;_blank&#34;&gt;lecture I&lt;/a&gt;) (&lt;a href=&#34;http://www.youtube.com/watch?v=6pBvbLyn6fE&#34; target=&#34;_blank&#34;&gt;lecture II&lt;/a&gt;) (&lt;a href=&#34;http://ai.berkeley.edu/slides/Lecture%208%20--%20MDPs%20I/SP14%20CS188%20Lecture%208%20--%20MDPs%20I.pptx&#34; target=&#34;_blank&#34;&gt;PPT I&lt;/a&gt;) (&lt;a href=&#34;http://ai.berkeley.edu/slides/Lecture%209%20--%20MDPs%20II/SP14%20CS188%20Lecture%209%20--%20MDPs%20II.pptx&#34; target=&#34;_blank&#34;&gt;PPT II&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Reinforcement Learning

&lt;ul&gt;
&lt;li&gt;(&lt;a href=&#34;http://www.youtube.com/watch?v=IXuHxkpO5E8&#34; target=&#34;_blank&#34;&gt;lecture I&lt;/a&gt;) (&lt;a href=&#34;http://www.youtube.com/watch?v=yNeSFbE1jdY&#34; target=&#34;_blank&#34;&gt;lecture II&lt;/a&gt;) (&lt;a href=&#34;http://ai.berkeley.edu/slides/Lecture%2010%20--%20Reinforcement%20Learning%20I/SP14%20CS188%20Lecture%2010%20--%20Reinforcement%20Learning%20I.pptx&#34; target=&#34;_blank&#34;&gt;PPT I&lt;/a&gt;) (&lt;a href=&#34;http://ai.berkeley.edu/slides/Lecture%2011%20--%20Reinforcement%20Learning%20II/SP14%20CS188%20Lecture%2011%20--%20Reinforcement%20Learning%20II.pptx&#34; target=&#34;_blank&#34;&gt;PPT II&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

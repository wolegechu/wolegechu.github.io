<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Yuchu Luo - 罗宇矗</title>
    <link>/post/</link>
    <description>Recent content in Posts on Yuchu Luo - 罗宇矗</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Yuchu Luo</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/post/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>[OS Notes] Processes</title>
      <link>/post/processes/</link>
      <pubDate>Mon, 01 Jan 2018 00:38:00 +0000</pubDate>
      
      <guid>/post/processes/</guid>
      <description>

&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#unic-centric-user-view-of-processes&#34;&gt;(UNIC-centric) User view of processes&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#creating-processes&#34;&gt;Creating processes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deleting-processes&#34;&gt;Deleting processes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#running-programs&#34;&gt;Running programs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#manipulating-file-descriptors&#34;&gt;Manipulating file descriptors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#pipes&#34;&gt;Pipes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#why-fork&#34;&gt;Why fork?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#kernel-view-of-processes&#34;&gt;Kernel view of processes&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#implementing-processes&#34;&gt;Implementing processes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#process-states&#34;&gt;Process states&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scheduling&#34;&gt;Scheduling&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#policy&#34;&gt;Policy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#preemption&#34;&gt;Preemption&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#context-switch&#34;&gt;Context switch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#threads&#34;&gt;Threads&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#threads-package-api&#34;&gt;Threads package API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#kernel-threads&#34;&gt;Kernel threads&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#limitation-of-kernel-level-threads&#34;&gt;Limitation of kernel-level threads&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#alternative-user-threads&#34;&gt;Alternative: User threads&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#implementing-user-level-threads&#34;&gt;Implementing user-level threads&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#thread-implementation-details&#34;&gt;Thread implementation details&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#backgroud&#34;&gt;Backgroud&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#calling-conventions&#34;&gt;Calling conventions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#procedure-calls&#34;&gt;Procedure calls&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#pintos-thread-implementation&#34;&gt;Pintos thread implementation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#i386-switch-threads&#34;&gt;i386 switch_threads&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#limitations-of-user-level-threads&#34;&gt;Limitations of user-level threads&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#user-threads-on-kernel-threads&#34;&gt;User threads on kernel threads&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#limitation-of-n-m-threading&#34;&gt;Limitation of n:m threading&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#lessons&#34;&gt;Lessons&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/nav&gt;


&lt;h2 id=&#34;unic-centric-user-view-of-processes&#34;&gt;(UNIC-centric) User view of processes&lt;/h2&gt;

&lt;h3 id=&#34;creating-processes&#34;&gt;Creating processes&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Original UNIX paper&lt;/strong&gt; is a great reference on core system calls

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;int fork (void);&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Create new process that is exact copy of current one&lt;/li&gt;
&lt;li&gt;Returen &lt;em&gt;process ID&lt;/em&gt; of new process in &amp;ldquo;parent&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Return 0 in &amp;ldquo;child&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;int waitpid (int pid, int *stat, int opt);&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;pid - process to wait for, or -1 for any&lt;/li&gt;
&lt;li&gt;stat - will contain exit value, or signal&lt;/li&gt;
&lt;li&gt;opt - usually 0 or WNOHANG&lt;/li&gt;
&lt;li&gt;Returns process ID or -1 on error&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;deleting-processes&#34;&gt;Deleting processes&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;void exit (int status);&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Current process ceases to exist&lt;/li&gt;
&lt;li&gt;&lt;em&gt;status&lt;/em&gt; shows up in &lt;em&gt;waitpid&lt;/em&gt; (shifted)&lt;/li&gt;
&lt;li&gt;By convention, status of 0 is success, non-zero error&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;int kill (int pid, int sig)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Sends signal &lt;em&gt;sig&lt;/em&gt; to process &lt;em&gt;pid&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;SIGTERM&lt;/em&gt; most common value, kills process by default (but application can catch it for &amp;ldquo;cleanup&amp;rdquo;)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;SIGKILL&lt;/em&gt; stronger, kills process always&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;running-programs&#34;&gt;Running programs&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;int execve (char *prog, char **argv, char **envp);&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;prog - full pathname of program to run&lt;/li&gt;
&lt;li&gt;argv - argument vector that gets passed to &lt;em&gt;main&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;envp - environment variables, e.g., PATH, HOME&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Generally called through a wrapper functions

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;int execvp (char *prog, char **argv);&lt;/code&gt; Search PATH for prog, use current environment&lt;/li&gt;
&lt;li&gt;&lt;code&gt;int execlp (char *prog, char *arg, ...);&lt;/code&gt; List arguments one at a time, finish with &lt;em&gt;NULL&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Warning: Pintos exec more like combined fork/exec&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Simplified minish.c&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;pid_t pid; char **av;
void do exec(){
    execvp (av[0], av);
    perror (av[0]);
    exit (1);
}
/* ... main loop: */
for (;;) {
    parse_next_line_of_input (&amp;amp;av, stdin)
    switch (pid = fork()) {
        case -1:
            perror (&amp;quot;fork&amp;quot;); break;
        case 0:
            doexec();
        default:
            waitpid (pid, NULL, o); break;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;manipulating-file-descriptors&#34;&gt;Manipulating file descriptors&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;int dup2 (int oldfd, int newfd);&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Closes &lt;em&gt;newfd&lt;/em&gt;, if it was a valid descriptor&lt;/li&gt;
&lt;li&gt;Makes &lt;em&gt;newfd&lt;/em&gt; an exact copy of &lt;em&gt;oldfd&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Two file descriptors will share some offset (lseek on one will affect both)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;int fcntl (int fd, F_SETFD, int val)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Sets &lt;em&gt;close on exec&lt;/em&gt; flag if val = 1, clears if val = 0&lt;/li&gt;
&lt;li&gt;Make file descriptor non-inheritable by spawned programs&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Example: redirsh.c

&lt;ul&gt;
&lt;li&gt;Loop that reads a command and executes it&lt;/li&gt;
&lt;li&gt;Recognizes command &amp;lt; input &amp;gt; output 2&amp;gt; errlog&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;void doexec (void) {
    int fd;
    if (infile) {  /* non-NULL for &amp;quot;command &amp;lt; infile&amp;quot; */
        if ((fd = open (infile, O_RDONLY)) &amp;lt; 0){
            perror (infile);
            exit (1);
        }
        if (fd != 0) {
            dup2 (fd, 0);
            close (fd);
        }
    }

    /* ... do same for outfile-&amp;gt;fd 1, errfile-&amp;gt;fd 2 ... */
    execvp (av[0], av);
    perror (av[0]);
    exit(1);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;pipes&#34;&gt;Pipes&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;int pipe (int fds[2]);&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Returns two descriptors in &lt;em&gt;fds[0]&lt;/em&gt; and &lt;em&gt;fds[1]&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Data written to &lt;em&gt;fds[1]&lt;/em&gt; will be returned by &lt;em&gt;read&lt;/em&gt; on &lt;em&gt;fds[0]&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;When last copy of fds[1] closed, fds[0] will return &lt;em&gt;EOF&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Returns 0 on success, -1 on error&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Operations on pipes

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;read/write/close&lt;/em&gt; - as with files&lt;/li&gt;
&lt;li&gt;When &lt;em&gt;fds[1]&lt;/em&gt; closed, read(fds[0]) returns 0 bytes&lt;/li&gt;
&lt;li&gt;When &lt;em&gt;fds[0]&lt;/em&gt; closed, write(fds[1]):

&lt;ul&gt;
&lt;li&gt;Kills process with SIGPIPE&lt;/li&gt;
&lt;li&gt;Or if signal ignored, fails with EPIPE&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Example: pipesh.c

&lt;ul&gt;
&lt;li&gt;Stes up pipeline command1 | command2 | command3 &amp;hellip;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;void doexec (void) {
    while (outcmd) {
        int pipefds[2]; pipe (pipefds);
        switch (fork()){
            case -1:
                perror (&amp;quot;fork&amp;quot;); exit (1);
            case 0:
                dup2 (pipefds[1], 1);
                close (pipefds[0]); close (pipefds[1]);
                outcmd = NULL;
                break;
            default:
                dup2 (pipefds[0], 0);
                close (pipefds[0]); close (pipdefds[1]);
                parse_command_line (&amp;amp;av, &amp;amp;outcomd, outcomd);
                break;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;why-fork&#34;&gt;Why fork?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Most calls to &lt;em&gt;fork&lt;/em&gt; followed by &lt;em&gt;execve&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Could also combine into one &lt;em&gt;spawn&lt;/em&gt; system call (like Pintos exec)&lt;/li&gt;
&lt;li&gt;Occasionally useful to fork one process

&lt;ul&gt;
&lt;li&gt;Unix &lt;em&gt;dump&lt;/em&gt; utility backs up file system to tape&lt;/li&gt;
&lt;li&gt;If tape fills up, must restart at some logical point&lt;/li&gt;
&lt;li&gt;Implemented by forking to revert to old state if tape ends&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Real win is simplicity of interface

&lt;ul&gt;
&lt;li&gt;Tons of things you might want to do to child: Manipulate file descriptors, set encironment variables, reduce privileges, &amp;hellip;&lt;/li&gt;
&lt;li&gt;Yet &lt;em&gt;fork&lt;/em&gt; requires no arguments at all&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Spawning a process without fork

&lt;ul&gt;
&lt;li&gt;Without fork, needs tons of different options for new process&lt;/li&gt;
&lt;li&gt;Example: Windows &lt;em&gt;CreateProcess&lt;/em&gt; System call&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;kernel-view-of-processes&#34;&gt;Kernel view of processes&lt;/h2&gt;

&lt;h3 id=&#34;implementing-processes&#34;&gt;Implementing processes&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Keep a data structure for each process

&lt;ul&gt;
&lt;li&gt;Process Control Block (PCB)&lt;/li&gt;
&lt;li&gt;Called &lt;em&gt;proc&lt;/em&gt; in Unix, &lt;em&gt;task_struct&lt;/em&gt; in Linux, and just &lt;em&gt;struct thread&lt;/em&gt; in Pintos&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Tracks &lt;em&gt;state&lt;/em&gt; of the process

&lt;ul&gt;
&lt;li&gt;Running, ready (runnable), waiting, etc.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Includes information necessary to run

&lt;ul&gt;
&lt;li&gt;Registers, virtual memory mappings, etc.&lt;/li&gt;
&lt;li&gt;Open files (including memory mapped files)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Various other data about the process

&lt;ul&gt;
&lt;li&gt;Credentials (user/group ID), signal mask, controlling terminal, priority, accounting statistics, whether being debugged, which system call binary emulation in use,..&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;process-states&#34;&gt;Process states&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/QQ20180102-100721.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Process can be in one of several states

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;new&lt;/em&gt; &amp;amp; &lt;em&gt;terminated&lt;/em&gt; at beginning &amp;amp; end of life&lt;/li&gt;
&lt;li&gt;&lt;em&gt;running&lt;/em&gt; - currently executing (or will execute on kernel return)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;ready&lt;/em&gt; - can run, but kernel has chosen different process to run&lt;/li&gt;
&lt;li&gt;&lt;em&gt;waiting&lt;/em&gt; - needs async event (e.g., disk operation)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Which process should kernel run?

&lt;ul&gt;
&lt;li&gt;if 0 runnable, run idle loop (or halt CPU), if 1 runnable, run it&lt;/li&gt;
&lt;li&gt;if &amp;gt; 1 runnable, must make scheduling decision&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;scheduling&#34;&gt;Scheduling&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;How to pick which process to run&lt;/li&gt;
&lt;li&gt;Scan process table for first runnable&lt;/li&gt;
&lt;li&gt;FIFO?&lt;/li&gt;
&lt;li&gt;Priority?&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;policy&#34;&gt;Policy&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Want to balance multiple goals

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Fairness&lt;/em&gt; - don&amp;rsquo;t starve processes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Priority&lt;/em&gt; - reflect relative importance of procs&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Deadlines&lt;/em&gt; - must do X (play audio) by certain time&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Throughput&lt;/em&gt; - want good overall performance&lt;/li&gt;
&lt;li&gt;&lt;em&gt;EfficiencyJ&lt;/em&gt; - minimize overhead of scheduler itself&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;No universal policy

&lt;ul&gt;
&lt;li&gt;Many variables, can&amp;rsquo;t optimize for all&lt;/li&gt;
&lt;li&gt;Conflicting goals (e.g., throughput or priority vs. fairness)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;preemption&#34;&gt;Preemption&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Can preempt a process when kernel gets control&lt;/li&gt;
&lt;li&gt;Running process can vector control to kernel

&lt;ul&gt;
&lt;li&gt;System call, page fault, illegal instruction, etc.&lt;/li&gt;
&lt;li&gt;May put current process to sleep&lt;/li&gt;
&lt;li&gt;May make other process runnable&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Periodic timer interrupt

&lt;ul&gt;
&lt;li&gt;If running process used up quantum, schedule another&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Device interrupt

&lt;ul&gt;
&lt;li&gt;Disk request completed, or packet arrived on network&lt;/li&gt;
&lt;li&gt;Previously waiting process becomes runnable&lt;/li&gt;
&lt;li&gt;Schedule if higher priority than current running proc.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Changing running process is called a &lt;em&gt;context switch&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;context-switch&#34;&gt;Context switch&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/QQ20180102-102427.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Very machine dependent. Typical things include:

&lt;ul&gt;
&lt;li&gt;Save program counter and integer registers (always)&lt;/li&gt;
&lt;li&gt;Save floating point or other special registers&lt;/li&gt;
&lt;li&gt;Save condition codes&lt;/li&gt;
&lt;li&gt;Change virtual address translations&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Non-negligible cost

&lt;ul&gt;
&lt;li&gt;Save/restore floating point registers expensive

&lt;ul&gt;
&lt;li&gt;Optimization: only save if process used floating point&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;May require flushing TLB (memory translation hardware)&lt;/li&gt;
&lt;li&gt;Usually causes more cache misses (switch working sets)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;threads&#34;&gt;Threads&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/QQ20180102-102842.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Most popular abstraction for concurrency

&lt;ul&gt;
&lt;li&gt;Lighter-weight abstraction than processes&lt;/li&gt;
&lt;li&gt;All threads in one process share memory, filed escriptors, etc.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Allows one process to use multiple CPUs or cores&lt;/li&gt;
&lt;li&gt;Allows program to overlap I/O and computation

&lt;ul&gt;
&lt;li&gt;Same benefit as OS running emacs &amp;amp; gcc simultaneously&lt;/li&gt;
&lt;li&gt;E.g., threaded web server services clients simultaneously:&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;for (;;) {
    fd = accept_client ();
    thread_create (service_client, &amp;amp;fd);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Most kernels have threads, too&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;threads-package-api&#34;&gt;Threads package API&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tid thread_create (void (*fn) (void *), void *);&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Create a new thread, run &lt;em&gt;fn&lt;/em&gt; with &lt;em&gt;arg&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;void thread_exit ();&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Destroy current thread&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;void thread_join (tid thread);&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Wait for thread &lt;em&gt;thread&lt;/em&gt; to exit&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Can have preemptive or non-preemptive threads

&lt;ul&gt;
&lt;li&gt;Preemptive causes more race conditions&lt;/li&gt;
&lt;li&gt;Non-preemptive can&amp;rsquo;t take advantage of multiple CPUs&lt;/li&gt;
&lt;li&gt;Before prevalent SMPs, most kernels non-preemptive&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;kernel-threads&#34;&gt;Kernel threads&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/QQ20180102-104119.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Can implement &lt;em&gt;thread_create&lt;/em&gt; as a system call&lt;/li&gt;
&lt;li&gt;To add &lt;em&gt;thread_create&lt;/em&gt; to an OS that doesn&amp;rsquo;t have it:

&lt;ul&gt;
&lt;li&gt;Start with process abstraction in kernel&lt;/li&gt;
&lt;li&gt;&lt;em&gt;thread_create&lt;/em&gt; like process creation with features stripped out

&lt;ul&gt;
&lt;li&gt;Keep same address space, file table, etc., in new process&lt;/li&gt;
&lt;li&gt;&lt;em&gt;rfork/clone&lt;/em&gt; syscalls actually allow individual control&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Faster than a process, but still very heacy weight&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;limitation-of-kernel-level-threads&#34;&gt;Limitation of kernel-level threads&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Every thread operation must go through kernel

&lt;ul&gt;
&lt;li&gt;create, exit, join, synchroniza, or switch for any reason&lt;/li&gt;
&lt;li&gt;On my laptop: syscall takes 100 cycles, fn call 5 cycles&lt;/li&gt;
&lt;li&gt;Result: threads 10x-30x slower when implemented in kernel&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;One-size fits all thread implementation

&lt;ul&gt;
&lt;li&gt;Kernel threads must please all people&lt;/li&gt;
&lt;li&gt;Maybe pay for fancy features (priority, etc.) you don&amp;rsquo;t need&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;General heavy-weight memory requirements

&lt;ul&gt;
&lt;li&gt;E.g., requires a fixed-size stack whthin kernel&lt;/li&gt;
&lt;li&gt;Other data structures desighned for heavier-weight processes&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;alternative-user-threads&#34;&gt;Alternative: User threads&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/QQ20180102-104743.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Implement as user-level library (a.k.a. &lt;em&gt;green&lt;/em&gt; threads)

&lt;ul&gt;
&lt;li&gt;One kernel thread per process&lt;/li&gt;
&lt;li&gt;&lt;em&gt;thread_create&lt;/em&gt;, &lt;em&gt;thread_exit&lt;/em&gt;, etc., just library functions&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;implementing-user-level-threads&#34;&gt;Implementing user-level threads&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Allocate a new stack for each &lt;em&gt;thread_create&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Keep a queue of runnable threads&lt;/li&gt;
&lt;li&gt;Replace networking system calls (read/write/etc.)

&lt;ul&gt;
&lt;li&gt;If operation would block, switch and run different thread&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Schedule periodic timer signal (setitimer)

&lt;ul&gt;
&lt;li&gt;Switch to another thread on timer signals&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Muti-threaded web server example

&lt;ul&gt;
&lt;li&gt;Thread calls &lt;em&gt;read&lt;/em&gt; to get data from remote web browser&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Fake&amp;rdquo; read &lt;em&gt;function&lt;/em&gt; makes read &lt;em&gt;syscall&lt;/em&gt; in non-blocking mode&lt;/li&gt;
&lt;li&gt;No data? schedule another thread&lt;/li&gt;
&lt;li&gt;On timer or when idle check which connections have new data&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;thread-implementation-details&#34;&gt;Thread implementation details&lt;/h2&gt;

&lt;h3 id=&#34;backgroud&#34;&gt;Backgroud&lt;/h3&gt;

&lt;h4 id=&#34;calling-conventions&#34;&gt;Calling conventions&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/1111.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Registers divided into 2 groups

&lt;ul&gt;
&lt;li&gt;Functions free to clobber &lt;strong&gt;caller-saved&lt;/strong&gt; regs (%eax [return val], %edx, &amp;amp;%ecx on x86)&lt;/li&gt;
&lt;li&gt;But must restore &lt;strong&gt;callee-saved&lt;/strong&gt; ones to original value upon return (on x86, %ebx, %esi, %edi, plus %ebp and %esp)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;sp&lt;/em&gt; register always base of stack

&lt;ul&gt;
&lt;li&gt;Frame pointer (fp) is old &lt;em&gt;sp&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Local variables stored in registers and on stack&lt;/li&gt;
&lt;li&gt;Function arguments go in caller-saved regs and on stack

&lt;ul&gt;
&lt;li&gt;with 32-bit x86, all arguments on stack&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;procedure-calls&#34;&gt;Procedure calls&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Procedure call&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;save active caller registers
call foo (pushes pc) -&amp;gt;
      save used callee registers
      &amp;hellip;do stuff&amp;hellip;
      restore callee saved registers
      jump back to calling function
      &amp;lt;-
restore caller registers&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Caller must save some state across function call

&lt;ul&gt;
&lt;li&gt;Return address, caller-saved registers&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Other state does not need to be saved

&lt;ul&gt;
&lt;li&gt;Calle-saved regs, global variables, stack pointer&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;pintos-thread-implementation&#34;&gt;Pintos thread implementation&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Implemente user processes on top of its own threads

&lt;ul&gt;
&lt;li&gt;Same technique can be used to implement user-level threads, too&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Per-thread state in thread control block structure&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;struct thread {
...
uint8_t *stack; /* Saved stack pointer. */
...
};
uint32_t thread_stack_ofs = offsetof(struct thread, stack)
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;C declaration for asm thread-switch function&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;struct thread *switch_threads (struct thread *cur, struct thread *next);
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Also thread initialization function to create new stack:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void thread_create (const char *name, thread_func *function, void *aux);
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;i386-switch-threads&#34;&gt;i386 switch_threads&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;pushl %ebx; pushl %ebp # Save callee-saved regs
pushl %esi; pushl %edi
mov thread_stack_ofs, %edx # %edx = offset of stack field
# in thread struct
movl 20(%esp), %eax # %eax = cur
movl %esp, (%eax,%edx,1) # cur-&amp;gt;stack = %esp
movl 24(%esp), %ecx # %ecx = next
movl (%ecx,%edx,1), %esp # %esp = next-&amp;gt;stack
popl %edi; popl %esi # Restore calle-saved regs
popl %ebp; popl %ebx
ret # Resume execution
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;limitations-of-user-level-threads&#34;&gt;Limitations of user-level threads&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;A user-level thread library can do the same thing as Pintos&lt;/li&gt;
&lt;li&gt;Can&amp;rsquo;t take advantage of multiple CPUs or cores&lt;/li&gt;
&lt;li&gt;A blocking system call blocks all threads

&lt;ul&gt;
&lt;li&gt;Can replace &lt;em&gt;read&lt;/em&gt; to handle network connections&lt;/li&gt;
&lt;li&gt;But usually OSes don&amp;rsquo;t let you do this for disk&lt;/li&gt;
&lt;li&gt;So one uncached disk read blocks all threads&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;A page fault blocks all threads&lt;/li&gt;
&lt;li&gt;Possible deadlock if one thread blocks on another&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;user-threads-on-kernel-threads&#34;&gt;User threads on kernel threads&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;User threads implemented on kernel threads

&lt;ul&gt;
&lt;li&gt;Multiple kernel-level threads per process&lt;/li&gt;
&lt;li&gt;&lt;em&gt;thread_create, thread_exit&lt;/em&gt; still library functions as before&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Sometimes called &lt;em&gt;n:m&lt;/em&gt; threading

&lt;ul&gt;
&lt;li&gt;Have &lt;em&gt;n&lt;/em&gt; user threads per &lt;em&gt;m&lt;/em&gt; kernel threads (simple user-level threads are n:1, kernel threads 1:1)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;limitation-of-n-m-threading&#34;&gt;Limitation of n:m threading&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Many of same problems as n:1 threads

&lt;ul&gt;
&lt;li&gt;Blocked threads, deadlock&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Hard to keep same # kthreads as availabel CPUs

&lt;ul&gt;
&lt;li&gt;Kernel knows how many CPUs available&lt;/li&gt;
&lt;li&gt;Kernel knows which kernel-level threads are blocked&lt;/li&gt;
&lt;li&gt;But tries to hide these things from applications for transparency&lt;/li&gt;
&lt;li&gt;So user-level thread scheduler might think a thread is running while underlying kernel thread is blocked&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Kernel doesn&amp;rsquo;t know relative importance of threads

&lt;ul&gt;
&lt;li&gt;Might preempt kthread in which library holds important lock&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;lessons&#34;&gt;Lessons&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Threads best implemented as a library

&lt;ul&gt;
&lt;li&gt;But kernel threads not best interface on which to do this&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Better kernel interface have been suggested

&lt;ul&gt;
&lt;li&gt;Scheduler Activations&lt;/li&gt;
&lt;li&gt;Maybe too complex to implement on exisiting OSes (some have added then removed such features, now Windows is trying it)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Standard threads still fine for most purposes

&lt;ul&gt;
&lt;li&gt;Use kernel threads if I/O concurrency main goal&lt;/li&gt;
&lt;li&gt;Use n:m threads for highly concurrent (e.g., sicentific applications) with many threads switches&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;But concurrency greatly increases complexity&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>[OS Notes] Synchronization (Part I)</title>
      <link>/post/synchronization_1/</link>
      <pubDate>Mon, 01 Jan 2018 00:38:00 +0000</pubDate>
      
      <guid>/post/synchronization_1/</guid>
      <description>

&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#cache-coherence-the-hardware-view&#34;&gt;Cache coherence (the hardware view)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#multicore-caches&#34;&gt;Multicore Caches&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#mesi-coherence-protocol&#34;&gt;MESI coherence protocol&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#core-and-bus-actions&#34;&gt;Core and Bus Actions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cc-numa&#34;&gt;cc-NUMA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#real-world-coherence-costs&#34;&gt;Real World Coherence Costs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/nav&gt;


&lt;h2 id=&#34;cache-coherence-the-hardware-view&#34;&gt;Cache coherence (the hardware view)&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Important memory system properties

&lt;ul&gt;
&lt;li&gt;Coherence - concerns accesses to a single memory location

&lt;ul&gt;
&lt;li&gt;Must obey program order if access from only CPU&lt;/li&gt;
&lt;li&gt;There is a total order on all updates&lt;/li&gt;
&lt;li&gt;There is bounded latency before everyone sees a write&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Consistency - concerns ordering across memory locations

&lt;ul&gt;
&lt;li&gt;Even with coherence, different CPUs can see the same write happen at different times&lt;/li&gt;
&lt;li&gt;Sequential consistency is what matches our intuition (As if instructions from all CPUs interleaved on one CPU)&lt;/li&gt;
&lt;li&gt;Many architectures offer weaker consistency can still be sufficient to implement thread API&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;multicore-caches&#34;&gt;Multicore Caches&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Performance requires caches

&lt;ul&gt;
&lt;li&gt;Divided into chuncks of bytes called lines (e.g., 64 bytes)&lt;/li&gt;
&lt;li&gt;Caches create an opportunity for cores to disagree about memory&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Bus-based approaches

&lt;ul&gt;
&lt;li&gt;&amp;ldquo;Snoopy&amp;rdquo; protocols, each CPU listens to memory bus&lt;/li&gt;
&lt;li&gt;Use write-through and invalidate when you see a write bits&lt;/li&gt;
&lt;li&gt;Bus-based schemes limit scalability&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Modern CPUs use networks (e.g., hypertransport, QPI)

&lt;ul&gt;
&lt;li&gt;CPUs pass each other messages about cache lines&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;mesi-coherence-protocol&#34;&gt;MESI coherence protocol&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Modified

&lt;ul&gt;
&lt;li&gt;One cache has a valid copy&lt;/li&gt;
&lt;li&gt;That copy is dirty (needs to be written back to memory)&lt;/li&gt;
&lt;li&gt;Must invalidate all copies in other caches before entering this state&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Exclusive

&lt;ul&gt;
&lt;li&gt;Same as Modified except the cache copy is clean&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Shared

&lt;ul&gt;
&lt;li&gt;One or more caches and memory have a valid copy&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Invalid

&lt;ul&gt;
&lt;li&gt;Doesn&amp;rsquo;t contain any data&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Owned (for enhanced &amp;ldquo;MOESI&amp;rdquo; protocal)

&lt;ul&gt;
&lt;li&gt;Memory may contain stale value of data (like Modified state)&lt;/li&gt;
&lt;li&gt;But have to broadcast modifications (sort of like Shared state)&lt;/li&gt;
&lt;li&gt;Can have both one owned and mutiple shared copies of cache line&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;core-and-bus-actions&#34;&gt;Core and Bus Actions&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Core

&lt;ul&gt;
&lt;li&gt;Read&lt;/li&gt;
&lt;li&gt;Write&lt;/li&gt;
&lt;li&gt;Evict (modified? must write back)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Bus

&lt;ul&gt;
&lt;li&gt;Read: without intent to modify, data can come from memory or another cache&lt;/li&gt;
&lt;li&gt;Read-exclusive: with intent to modify, must invalidate all other cache copies&lt;/li&gt;
&lt;li&gt;Writeback: contens put on bus and memory is updated&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;cc-numa&#34;&gt;cc-NUMA&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Old machines used &lt;em&gt;dance hall&lt;/em&gt; achitectures

&lt;ul&gt;
&lt;li&gt;Any CPU can &amp;ldquo;dance with&amp;rdquo; any memory equally&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;An alternative: Non-Uniform Memory Access

&lt;ul&gt;
&lt;li&gt;Each CPU has fast access to some &amp;ldquo;close&amp;rdquo; memory&lt;/li&gt;
&lt;li&gt;Slower to access memory that is farther away&lt;/li&gt;
&lt;li&gt;Use a directory to keep track of who is caching what&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Originally for esoteric machines with many CPUs

&lt;ul&gt;
&lt;li&gt;But AMD and then Intel integrated memory controller into CPU&lt;/li&gt;
&lt;li&gt;Faster to access memory controlled by the local socket (or even local die in a multi-chip module)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;cc-NUMA = cache-coherent non-uniform memory access

&lt;ul&gt;
&lt;li&gt;Rarely see non-cache-coherent NUMA&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;real-world-coherence-costs&#34;&gt;Real World Coherence Costs&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;If another core in same socket holds line in modified state:

&lt;ul&gt;
&lt;li&gt;load: 109 cycles&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>[OS Notes] Virtual Memory OS</title>
      <link>/post/vm_os/</link>
      <pubDate>Wed, 27 Dec 2017 00:38:00 +0000</pubDate>
      
      <guid>/post/vm_os/</guid>
      <description>

&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#paging&#34;&gt;Paging&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#working-set-model&#34;&gt;Working set model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#paging-challenge&#34;&gt;Paging challenge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#re-starting-instructions&#34;&gt;Re-starting instructions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#what-to-fetch&#34;&gt;What to fetch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#selecting-physical-pages&#34;&gt;Selecting physical pages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#superpages&#34;&gt;Superpages&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#eviction-policies&#34;&gt;Eviction policies&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#starw-man-fifo-eviction&#34;&gt;Starw man: FIFO eviction&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#thrashing&#34;&gt;Thrashing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#details-of-paging&#34;&gt;Details of paging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-user-level-perspective&#34;&gt;The user-level perspective&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#case-study-4-4-bsd&#34;&gt;Case study: 4.4 BSD&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/nav&gt;


&lt;h2 id=&#34;paging&#34;&gt;Paging&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/WX20171227-110059.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use disk to simulate larger virtual than physical memory&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;working-set-model&#34;&gt;Working set model&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Disk much, much slower than memory

&lt;ul&gt;
&lt;li&gt;Goal: run at memory speed, not disk speed&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;sup&gt;80&lt;/sup&gt;&amp;frasl;&lt;sub&gt;20&lt;/sub&gt; rule: 20% of memory gets 80% of memory accesses

&lt;ul&gt;
&lt;li&gt;Keep the hot 20% in memory&lt;/li&gt;
&lt;li&gt;Keep the cold 80% on disk&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;paging-challenge&#34;&gt;Paging challenge&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;How to resume a process after a fault?

&lt;ul&gt;
&lt;li&gt;Need to save state and resume&lt;/li&gt;
&lt;li&gt;Process might have been in the middle of an instruction!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;What to fetch from disk?

&lt;ul&gt;
&lt;li&gt;Just needed page or more?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;What to eject?

&lt;ul&gt;
&lt;li&gt;How to allocate physical pages amongst processes?&lt;/li&gt;
&lt;li&gt;Wchich of a particular process&amp;rsquo;s pages to keep in memory?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;re-starting-instructions&#34;&gt;Re-starting instructions&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Hardware provides kernel with information about page fault

&lt;ul&gt;
&lt;li&gt;Faulting virtual address (In &lt;code&gt;%cr2&lt;/code&gt; reg on x86&amp;ndash;may see it if you midify Pintos &lt;code&gt;page_fault&lt;/code&gt; and use &lt;code&gt;fault_addr&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Address of instruction that caused fault&lt;/li&gt;
&lt;li&gt;Was the access a read or write? Was it an instruction fetch? Was it caused by user accss to kernel-only memory?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Hardware mush allow resuming after a fault&lt;/li&gt;
&lt;li&gt;Idempotent instructions are easy

&lt;ul&gt;
&lt;li&gt;E.g., simple load or store instruction can be restarted&lt;/li&gt;
&lt;li&gt;Just re-execute any instruction that only accesses one address&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Complex instructions must be re-started, too

&lt;ul&gt;
&lt;li&gt;E.g., x86 move string instructions&lt;/li&gt;
&lt;li&gt;Specify src, dst, count in &lt;code&gt;%esi, %edi, %ecx&lt;/code&gt; registers&lt;/li&gt;
&lt;li&gt;On fault, registers adjusted to resume where move left off&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;what-to-fetch&#34;&gt;What to fetch&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Bring in page that caused page fault&lt;/li&gt;
&lt;li&gt;Pre-fetch surrounding pages?

&lt;ul&gt;
&lt;li&gt;Reading two disk blocks approximately as fast as reading one&lt;/li&gt;
&lt;li&gt;As long as no track/head switch, seek time dominates&lt;/li&gt;
&lt;li&gt;If application exhibits spacial locality, then big win to store and read multiple contiguous pages&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Also pre-zero unused pages in idle loop

&lt;ul&gt;
&lt;li&gt;Need 0-filled pages for stack, heap, anonymously mmapped memory&lt;/li&gt;
&lt;li&gt;Zeroing them only on demand is slower&lt;/li&gt;
&lt;li&gt;Hence, many OSes zero freed pages while CPU is idle&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;selecting-physical-pages&#34;&gt;Selecting physical pages&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;May need to eject some pages

&lt;ul&gt;
&lt;li&gt;More on eviction policy in two slides&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;May also have a choice of physical pages&lt;/li&gt;
&lt;li&gt;Direct-mapped physical caches

&lt;ul&gt;
&lt;li&gt;Virtual -&amp;gt; Physical mapping can affect performance&lt;/li&gt;
&lt;li&gt;In old days: Physical adddredd A conflicts with $kC+A$ (where k is any integer, C is cache size)&lt;/li&gt;
&lt;li&gt;Applications can conflict with each other or themselves&lt;/li&gt;
&lt;li&gt;Scientific application benefit if consecutive virtual pages do not confilict in the cache&lt;/li&gt;
&lt;li&gt;Many other applications do better with random mapping&lt;/li&gt;
&lt;li&gt;There days: CPUs more sophisticated than kC + A&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;superpages&#34;&gt;Superpages&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;How should OS make use of &amp;ldquo;large&amp;rdquo; mappings

&lt;ul&gt;
&lt;li&gt;x86 has &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt; MB pages that might be useful&lt;/li&gt;
&lt;li&gt;Alpha has even more choices: 8KB, 64KB, 512KB, 4MB&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Sometimes more pages in L2 cache than TLB entries

&lt;ul&gt;
&lt;li&gt;Don&amp;rsquo;t want costly TLB misses going to main memory&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Or have two-level TLBs

&lt;ul&gt;
&lt;li&gt;Want to maximize hit rate in faster L1 TLB&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;OS can transparently support superpages

&lt;ul&gt;
&lt;li&gt;&amp;ldquo;reserve&amp;rdquo; appropriate physical pages if possible&lt;/li&gt;
&lt;li&gt;Promote contiguous pages to superpages&lt;/li&gt;
&lt;li&gt;Does complicate evicting (esp. dirty pages) - demote&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;eviction-policies&#34;&gt;Eviction policies&lt;/h2&gt;

&lt;h3 id=&#34;starw-man-fifo-eviction&#34;&gt;Starw man: FIFO eviction&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Evict oldest fetched page in system&lt;/li&gt;
&lt;li&gt;Example-reference string 1,2,3,4,1,2,5,1,2,3,4,5&lt;/li&gt;
&lt;li&gt;3 physical pages: 9 page faults&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;thrashing&#34;&gt;Thrashing&lt;/h2&gt;

&lt;h2 id=&#34;details-of-paging&#34;&gt;Details of paging&lt;/h2&gt;

&lt;h2 id=&#34;the-user-level-perspective&#34;&gt;The user-level perspective&lt;/h2&gt;

&lt;h2 id=&#34;case-study-4-4-bsd&#34;&gt;Case study: 4.4 BSD&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>[OS Notes] Virtual Memory Hardware</title>
      <link>/post/vm_hardware/</link>
      <pubDate>Tue, 26 Dec 2017 00:38:00 +0000</pubDate>
      
      <guid>/post/vm_hardware/</guid>
      <description>

&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#issues-in-sharing-physical-memory&#34;&gt;Issues in sharing physical memory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#virtual-memory&#34;&gt;Virtual memory&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#goals&#34;&gt;goals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#virtual-memory-advantages&#34;&gt;Virtual memory advantages&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ideas&#34;&gt;Ideas&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#ideal-1-load-time-linking&#34;&gt;Ideal 1: load-time linking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ideal-2-base-bound-register&#34;&gt;Ideal 2: base + bound register&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#definition&#34;&gt;Definition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#base-bound&#34;&gt;Base + bound&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#trade-offs&#34;&gt;Trade-offs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#segmentation&#34;&gt;Segmentation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#segmentation-mechanics&#34;&gt;Segmentation mechanics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#segmentation-example&#34;&gt;Segmentation example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#trade-offs-1&#34;&gt;Trade-offs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#fragmentation&#34;&gt;Fragmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#alternatives-to-hardware-mmu&#34;&gt;Alternatives to hardware MMU&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#paging&#34;&gt;Paging&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#trade-offs-2&#34;&gt;Trade-offs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#simplified-allocation&#34;&gt;Simplified allocation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#paging-data-structures&#34;&gt;Paging data structures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-paging-on-pdp-11&#34;&gt;Example: Paging on PDP-11&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/nav&gt;


&lt;h2 id=&#34;issues-in-sharing-physical-memory&#34;&gt;Issues in sharing physical memory&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/WX20171226-152306.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Protection

&lt;ul&gt;
&lt;li&gt;A bug in one process can corrupt in another&lt;/li&gt;
&lt;li&gt;Must somehow prevent process A from trashing B&amp;rsquo;s memory&lt;/li&gt;
&lt;li&gt;Also prevent A from even observing B&amp;rsquo;s memory (ssh-agent)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Transparency

&lt;ul&gt;
&lt;li&gt;A process shouldn&amp;rsquo;t require particular physical memory bits&lt;/li&gt;
&lt;li&gt;Yet processes often require large amounts of contiguous memory (for stack, large data structures, etc.)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Resource exhaustion

&lt;ul&gt;
&lt;li&gt;Programmers typically assume machine has &amp;ldquo;enough&amp;rdquo; memory&lt;/li&gt;
&lt;li&gt;Sum of sizes of all processes often greater than physical memory&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;virtual-memory&#34;&gt;Virtual memory&lt;/h2&gt;

&lt;h3 id=&#34;goals&#34;&gt;goals&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Give each program its own &lt;em&gt;virtual&lt;/em&gt; address space

&lt;ul&gt;
&lt;li&gt;At runtime, &lt;strong&gt;Memory-Management Unit (MMU)&lt;/strong&gt; relocates each load/store&lt;/li&gt;
&lt;li&gt;Application doesn&amp;rsquo;t see physical memory addresses&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Also enforce protection

&lt;ul&gt;
&lt;li&gt;Prevent one app from messing with another&amp;rsquo;s memory&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;And allow programs to see more memory than exists

&lt;ul&gt;
&lt;li&gt;Somehow relocate some memory accesses to disk&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;virtual-memory-advantages&#34;&gt;Virtual memory advantages&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Can relocate program while running

&lt;ul&gt;
&lt;li&gt;Run partially in memory, partially on disk&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Most of a process&amp;rsquo;s memory may be idle (&lt;sup&gt;80&lt;/sup&gt;&amp;frasl;&lt;sub&gt;20&lt;/sub&gt; rule)

&lt;ul&gt;
&lt;li&gt;&lt;img src=&#34;/img/post/WX20171226-153927.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;Write idle parts to disk until needed&lt;/li&gt;
&lt;li&gt;Let other processes use memory of idle part&lt;/li&gt;
&lt;li&gt;Like CPU virtualization: when process not using CPU, switch (Not using amemory region? switch it to another process)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Challenge: VM = extra layer, could be slow&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ideas&#34;&gt;Ideas&lt;/h2&gt;

&lt;h3 id=&#34;ideal-1-load-time-linking&#34;&gt;Ideal 1: load-time linking&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/WX20171226-154928.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Linker&lt;/em&gt; patches addresses of symbols like printf&lt;/li&gt;
&lt;li&gt;Idea: link when process executed, not at compile time

&lt;ul&gt;
&lt;li&gt;Determine where process will reside in memory&lt;/li&gt;
&lt;li&gt;Adjust all refernces within program (using addtion)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Problems?

&lt;ul&gt;
&lt;li&gt;How to enforce protection?&lt;/li&gt;
&lt;li&gt;How to move once already in memory? (consider data pointers)&lt;/li&gt;
&lt;li&gt;What if no contiguous free region fits program?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;ideal-2-base-bound-register&#34;&gt;Ideal 2: base + bound register&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/WX20171226-163437.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Two special privileged registers: &lt;strong&gt;base&lt;/strong&gt; snf &lt;strong&gt;bound&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;On each load/store/jump:

&lt;ul&gt;
&lt;li&gt;Physical address = virtual address + base&lt;/li&gt;
&lt;li&gt;Check 0 ≤ vitual address ≤ bound, else trap to kernel&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;How to move process in memory?

&lt;ul&gt;
&lt;li&gt;Change base register&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;What happens on context switch?

&lt;ul&gt;
&lt;li&gt;OS must re-load base and bound register&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;definition&#34;&gt;Definition&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Programs load/store to &lt;code&gt;virtual addresses&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Actual memory uses &lt;code&gt;physical addresses&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;VM Hardware is Memory Management Unit (&lt;code&gt;MMU&lt;/code&gt;)

&lt;ul&gt;
&lt;li&gt;Usually part of CPU&lt;/li&gt;
&lt;li&gt;Configured through privileged instructions (e.g., load bound reg)&lt;/li&gt;
&lt;li&gt;Translates from virtual to physical addresses&lt;/li&gt;
&lt;li&gt;Gives per-process view of memory called &lt;code&gt;address space&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;base-bound&#34;&gt;Base + bound&lt;/h2&gt;

&lt;h3 id=&#34;trade-offs&#34;&gt;Trade-offs&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Advantages

&lt;ul&gt;
&lt;li&gt;Cheap in terms of hardware: only two registers&lt;/li&gt;
&lt;li&gt;Cheap in terms of cycles: do add and compare in parallel&lt;/li&gt;
&lt;li&gt;Examples: Cray-1 used this scheme&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Disadvantages

&lt;ul&gt;
&lt;li&gt;Growing a process is expensive or impossible&lt;/li&gt;
&lt;li&gt;No way to share code or data (E.g., two copies of bochs, both running pintos)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;One solution: Multiple segments

&lt;ul&gt;
&lt;li&gt;E.g., separate code, stack, data segments&lt;/li&gt;
&lt;li&gt;Possibly multiple data segments&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;segmentation&#34;&gt;Segmentation&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/WX20171226-164915.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Let processes have many base/bound regs

&lt;ul&gt;
&lt;li&gt;Address space built from many segments&lt;/li&gt;
&lt;li&gt;Can share/protect memory at segment granularity&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Must specify segment as part of virtual address&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;segmentation-mechanics&#34;&gt;Segmentation mechanics&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/WX20171226-191449.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Each process has a segment table&lt;/li&gt;
&lt;li&gt;Each VA (Virtual Address) indicates a segment and offset:

&lt;ul&gt;
&lt;li&gt;Top bits of addr select segment, low bits select offset (PDP-10)&lt;/li&gt;
&lt;li&gt;Or segment selected by instruction or operand (means you need wider &amp;ldquo;far&amp;rdquo; pointers to specify segment)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;segmentation-example&#34;&gt;Segmentation example&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/WX20171226-192145.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2-bit segment number (1st digit), 12 bit offset (last 3)

&lt;ul&gt;
&lt;li&gt;Where is 0x0&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;trade-offs-1&#34;&gt;Trade-offs&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Advantages

&lt;ul&gt;
&lt;li&gt;Multiple segments per process&lt;/li&gt;
&lt;li&gt;Allows sharing!&lt;/li&gt;
&lt;li&gt;Don&amp;rsquo;t need entire process in memory&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Disadvantages

&lt;ul&gt;
&lt;li&gt;Requires translation hardware, which could limit performance&lt;/li&gt;
&lt;li&gt;Segments not completely transparent to program (e.g., default segment faster or uses shorter instruction)&lt;/li&gt;
&lt;li&gt;$n$ byte segment needs &lt;em&gt;n contiguous&lt;/em&gt; bytes of physical memory&lt;/li&gt;
&lt;li&gt;Makes &lt;em&gt;fragmentation&lt;/em&gt; a real problem&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;fragmentation&#34;&gt;Fragmentation&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Fragmentation =&amp;gt; Inability to use free memory&lt;/li&gt;
&lt;li&gt;Over time:

&lt;ul&gt;
&lt;li&gt;Variable-sized pices = many small holes (external fragmentation)&lt;/li&gt;
&lt;li&gt;Fixed-sized pieces = no external holes, but force internal waste (internal fragmentation)
&lt;img src=&#34;/img/post/WX20171226-213655.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;alternatives-to-hardware-mmu&#34;&gt;Alternatives to hardware MMU&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Language-level protection (Java)

&lt;ul&gt;
&lt;li&gt;Single address space for different modules&lt;/li&gt;
&lt;li&gt;Language enforces isolation&lt;/li&gt;
&lt;li&gt;Singularity OS does this&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Software fault isolation

&lt;ul&gt;
&lt;li&gt;Instrument compiler output&lt;/li&gt;
&lt;li&gt;Checks before ever ystore operation prevents modules from trashing each other&lt;/li&gt;
&lt;li&gt;Google Native Client does this&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;paging&#34;&gt;Paging&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Divede memory up into small &lt;em&gt;pages&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Map virtual pages to physical pages

&lt;ul&gt;
&lt;li&gt;Each process has separate mapping&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Allow OS to gain control on certain operation

&lt;ul&gt;
&lt;li&gt;Read-only pages trap to OS on write&lt;/li&gt;
&lt;li&gt;Invalid pages trap to OS on read or write&lt;/li&gt;
&lt;li&gt;OS can change mapping and resume application&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Other features sometimes found:

&lt;ul&gt;
&lt;li&gt;Hardware can set &amp;ldquo;accessed&amp;rdquo; and &amp;ldquo;dirty&amp;rdquo; bits&lt;/li&gt;
&lt;li&gt;Control page execute permission separately from read/write&lt;/li&gt;
&lt;li&gt;Control caching or memory consistency of page&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;trade-offs-2&#34;&gt;Trade-offs&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Eliminates external fragmentation&lt;/li&gt;
&lt;li&gt;Simplifies allocation, free, and backing storage (swap)&lt;/li&gt;
&lt;li&gt;Average internal fragmentation of .5 pages per &amp;ldquo;segment&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;simplified-allocation&#34;&gt;Simplified allocation&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Allocate any physical page to any process&lt;/li&gt;
&lt;li&gt;Can store idle virtual pages on disk&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;paging-data-structures&#34;&gt;Paging data structures&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Pages are fixed size, e.g., 4K

&lt;ul&gt;
&lt;li&gt;Least significant 12 ($log_{2}4K$) bits of address are page offset&lt;/li&gt;
&lt;li&gt;Most significant bits are &lt;em&gt;page number&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Each process has a page table

&lt;ul&gt;
&lt;li&gt;Maps &lt;em&gt;virtual page numbers (VPNs)&lt;/em&gt; to &lt;em&gt;physical page numbers (PPNS)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Also includes bits for protection, validity, etc.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;On memory access: Translate VPN to PPN, then add offset
&lt;img src=&#34;/img/post/WX20171227-094654.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;example-paging-on-pdp-11&#34;&gt;Example: Paging on PDP-11&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;64K virtual memory, 8K pages

&lt;ul&gt;
&lt;li&gt;Separate address space for instructions &amp;amp; data&lt;/li&gt;
&lt;li&gt;I.e., can&amp;rsquo;t read your own instructions with a load&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Entire page table stored in registers

&lt;ul&gt;
&lt;li&gt;8 Instruction page translation&lt;/li&gt;
&lt;li&gt;8 Data page translation&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Swap 16 machine registers on each context switch&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2017-12-12</title>
      <link>/post/til-2017-12-12/</link>
      <pubDate>Tue, 12 Dec 2017 00:38:00 +0000</pubDate>
      
      <guid>/post/til-2017-12-12/</guid>
      <description>

&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#note-deep-learning-practice-and-trends-nips-2017&#34;&gt;[Note] Deep Learning: Practice and Trends (NIPS 2017)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#practice&#34;&gt;Practice&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#architectures&#34;&gt;Architectures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#recurrent-nets&#34;&gt;Recurrent Nets&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#trends&#34;&gt;Trends&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#autoregressive-models&#34;&gt;Autoregressive Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#domain-alignment-unsupervised&#34;&gt;Domain Alignment (unsupervised)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#learning-to-learn-meta-learning&#34;&gt;Learning to Learn / Meta Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusions-and-expectations&#34;&gt;Conclusions and Expectations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/nav&gt;


&lt;h1 id=&#34;note-deep-learning-practice-and-trends-nips-2017&#34;&gt;[Note] Deep Learning: Practice and Trends (NIPS 2017)&lt;/h1&gt;

&lt;h2 id=&#34;practice&#34;&gt;Practice&lt;/h2&gt;

&lt;h3 id=&#34;architectures&#34;&gt;Architectures&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Convolutional Nets

&lt;ul&gt;
&lt;li&gt;Locality: objects tend to have a local spatial support

&lt;ul&gt;
&lt;li&gt;locally-connected&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Teanslation invariance: object appearance is independent of location&lt;/li&gt;
&lt;li&gt;Tricks of the Trade

&lt;ul&gt;
&lt;li&gt;Optimization

&lt;ul&gt;
&lt;li&gt;SGD with momentum&lt;/li&gt;
&lt;li&gt;Batch Norm&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Initialization

&lt;ul&gt;
&lt;li&gt;Weight init: start from the weights which lead to stable training&lt;/li&gt;
&lt;li&gt;Sample from zero-mean normal distribution w/ small variance 0.01

&lt;ul&gt;
&lt;li&gt;Adaptively choose variance for each layer

&lt;ul&gt;
&lt;li&gt;preserve gradient magnitude: 1/sqrt(fan_in)&lt;/li&gt;
&lt;li&gt;works fine for VGGNets (up to 20 layers), but not sufficient for deeper nets&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Model

&lt;ul&gt;
&lt;li&gt;Stacking 3x3 convolutions&lt;/li&gt;
&lt;li&gt;Inception&lt;/li&gt;
&lt;li&gt;ResNet adds modules which ensure that the gradient doesn&amp;rsquo;t vanish&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;recurrent-nets&#34;&gt;Recurrent Nets&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Two Key Ingredients: Neural Embeddings, Recurrent Language Models&lt;/li&gt;
&lt;li&gt;Dot product Attention

&lt;ul&gt;
&lt;li&gt;Inputs: &amp;ldquo;I am a cat&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Input RNN states: $e_1e_2e_3e_4$&lt;/li&gt;
&lt;li&gt;Decoder RNN state at step i (query): $h_i$&lt;/li&gt;
&lt;li&gt;Compute scalars $h_i^Te_1, h_i^Te_2,&amp;hellip;$representing similarity / relevance between encoder steps and query&lt;/li&gt;
&lt;li&gt;Normaliza $[h_i^Te_1,h_i^Te_2,&amp;hellip;]$ with softmax to produce attention weights&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Tricks of the Trade

&lt;ul&gt;
&lt;li&gt;Long sequences?

&lt;ul&gt;
&lt;li&gt;Attention&lt;/li&gt;
&lt;li&gt;Bigger state&lt;/li&gt;
&lt;li&gt;Reverse inputs&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Can&amp;rsquo;t overfit?

&lt;ul&gt;
&lt;li&gt;Bigger hidden state&lt;/li&gt;
&lt;li&gt;Deep LSTM + Skip Connections&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Overfit?

&lt;ul&gt;
&lt;li&gt;Dropout + Ensembles&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Tuning

&lt;ul&gt;
&lt;li&gt;Keep calm and decrease your learning rate&lt;/li&gt;
&lt;li&gt;Initalization of parameters is critical (in seq2seq we used U(-0.05, 0.05))&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clip the gradients!&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;E.g. if ||grad|| &amp;gt; 5: grad = grad/||grad|| * 5&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Attention and Memory Toolbox

&lt;ul&gt;
&lt;li&gt;Read/Write memories (neural turing machine)&lt;/li&gt;
&lt;li&gt;Sequence Prediction&lt;/li&gt;
&lt;li&gt;Seq2Seq&lt;/li&gt;
&lt;li&gt;Temporal Hierarchies&lt;/li&gt;
&lt;li&gt;Multimodality&lt;/li&gt;
&lt;li&gt;Attention/Pointers&lt;/li&gt;
&lt;li&gt;Recurrent Architectures&lt;/li&gt;
&lt;li&gt;Key, Value memories&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;trends&#34;&gt;Trends&lt;/h2&gt;

&lt;h3 id=&#34;autoregressive-models&#34;&gt;Autoregressive Models&lt;/h3&gt;

&lt;p&gt;$$P(x;\theta) = \prod_{n=1}^N P(x_n|x_n;\theta)$$&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Each factor can be parametrized by $\theta$, which can be shared&lt;/li&gt;
&lt;li&gt;The variables can be arbitrarily ordered and grouped, as long as the ordering and grouping is consistent.&lt;/li&gt;
&lt;li&gt;Building Blocks

&lt;ul&gt;
&lt;li&gt;Inputs and Outpus: these can also be conditioning variables

&lt;ul&gt;
&lt;li&gt;Image pixels&lt;/li&gt;
&lt;li&gt;Text sequences&lt;/li&gt;
&lt;li&gt;Audio waveforms&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Architectures

&lt;ul&gt;
&lt;li&gt;Recurrent, over space and time&lt;/li&gt;
&lt;li&gt;Causal convolutions&lt;/li&gt;
&lt;li&gt;Causal conv + attention&lt;/li&gt;
&lt;li&gt;Attention-only!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Losses:

&lt;ul&gt;
&lt;li&gt;Discrete case: softmax cross entropy&lt;/li&gt;
&lt;li&gt;Continuous: Gaussian (mixture) likelihood&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mixture of logistics loss&lt;/strong&gt; (PixelCNN++ in ICLR 2017)

&lt;ul&gt;
&lt;li&gt;$$ v ~ \sum_{i=1}^K \pi_i logistic(\mu_i,s_i) $$&lt;/li&gt;
&lt;li&gt;$$ P(x|\pi,\mu,s) = \sum_{i=1}^K \pi_i[\sigma((x+0.5-\mu_i)/s_i) - \sigma((x-0.5-\mu_i) / s_i)] $$&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Autogressive scoring and sampling

&lt;ul&gt;
&lt;li&gt;Fully sequential models:

&lt;ul&gt;
&lt;li&gt;PixelCNN, PixelCNN++, WaveNet, &amp;hellip;&lt;/li&gt;
&lt;li&gt;O(1) scoring, O(N) sampling&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Models with conditional independence assumptions:

&lt;ul&gt;
&lt;li&gt;O(1) scoring, sampling can be O(1), O(log N), etc depending on cond. indep. assumptions&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Distilled models:

&lt;ul&gt;
&lt;li&gt;Parall WaveNet, Parallel NMT&lt;/li&gt;
&lt;li&gt;O(N) scoring, O(1) sampling&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;domain-alignment-unsupervised&#34;&gt;Domain Alignment (unsupervised)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Building Blocks

&lt;ul&gt;
&lt;li&gt;Inputs and Outpus

&lt;ul&gt;
&lt;li&gt;Sets of images with shared structure, but weak or no alignment&lt;/li&gt;
&lt;li&gt;Text corpora in different languages, but not parallel&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Architecures

&lt;ul&gt;
&lt;li&gt;Nothing fancy!&lt;/li&gt;
&lt;li&gt;For images: mostly convolutional nets&lt;/li&gt;
&lt;li&gt;For text: recurrent&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Losses

&lt;ul&gt;
&lt;li&gt;Latent space: Domain confusion&lt;/li&gt;
&lt;li&gt;Pixel space: Cycle consistency&lt;/li&gt;
&lt;li&gt;Both adversarial loss and likelihoods work!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Approach

&lt;ul&gt;
&lt;li&gt;Cross-modal retrieval&lt;/li&gt;
&lt;li&gt;Unsupervised domain transfer for classification&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Case

&lt;ul&gt;
&lt;li&gt;DiscoGAN - Car2Face&lt;/li&gt;
&lt;li&gt;GraspGAN&lt;/li&gt;
&lt;li&gt;Unsupervised Neural Machine Translation&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;learning-to-learn-meta-learning&#34;&gt;Learning to Learn / Meta Learning&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Building Blocks:

&lt;ul&gt;
&lt;li&gt;Inputs and Outputs: text, images, actions&lt;/li&gt;
&lt;li&gt;Architectures: Recurrent, CNN (+attention)&lt;/li&gt;
&lt;li&gt;Losses (loss based on another loss): Model, Optimization, Initialization&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Learning to learn:

&lt;ul&gt;
&lt;li&gt;What is Meta Learning?

&lt;ul&gt;
&lt;li&gt;Go beyond train/test from same distribution&lt;/li&gt;
&lt;li&gt;Task between train/test changes, so model has to &amp;ldquo;learn to learn&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Model Based, Metric Based, Optimization Based&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;conclusions-and-expectations&#34;&gt;Conclusions and Expectations&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Deep autoregressive models and ConvNets are ubiquitous and already useful in consumer applications&lt;/li&gt;
&lt;li&gt;Inductive biases are useful

&lt;ul&gt;
&lt;li&gt;spatial invariance for CNNs&lt;/li&gt;
&lt;li&gt;time recurrence for RNNs&lt;/li&gt;
&lt;li&gt;Permutation invariance for Graphs&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Simple tricks like ResNet will be discovered&lt;/li&gt;
&lt;li&gt;Adversarial networks and unsupervised domain adaptation have interesting market app (e.g. phone apps like style transfer)&lt;/li&gt;
&lt;li&gt;Meta learning: more and more of the model lifecycle (train/val/test) will be learned in an end-to-end way&lt;/li&gt;
&lt;li&gt;Program syntesis + Graph networks may be very important and find more real-world applications (e.g. RobustFill)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2017-12-08</title>
      <link>/post/til-2017-12-08/</link>
      <pubDate>Fri, 08 Dec 2017 00:38:00 +0000</pubDate>
      
      <guid>/post/til-2017-12-08/</guid>
      <description>

&lt;h2 id=&#34;paper-daily&#34;&gt;Paper Daily&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Where Classification Fails, Interpretation Rises

&lt;ul&gt;
&lt;li&gt;apply an attention mechanism to the adversarial examples detection&lt;/li&gt;
&lt;li&gt;uisng attention to defend against adversarial examples&lt;/li&gt;
&lt;li&gt;(this paper is hard to read)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Deep Image Prior

&lt;ul&gt;
&lt;li&gt;randomly-initialized neural network can be used as a handcrafted prior with excellent results&lt;/li&gt;
&lt;li&gt;search in parameter space&lt;/li&gt;
&lt;li&gt;apply untrianed CNN, fit a G network to a single degraded image.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Deep Reinforcement Learning framework for Autonoumous Driving

&lt;ul&gt;
&lt;li&gt;Deep Deterministic Actor Critic (DDAC)

&lt;ul&gt;
&lt;li&gt;actor: provides the policy mapping from a state to action&lt;/li&gt;
&lt;li&gt;critic: evaluates the value of the action taken (same as Q-function)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;review-of-clustering-algorithms&#34;&gt;Review of clustering algorithms&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Clustering

&lt;ul&gt;
&lt;li&gt;k-means&lt;/li&gt;
&lt;li&gt;k-medoids&lt;/li&gt;
&lt;li&gt;Gaussian Mixture Model&lt;/li&gt;
&lt;li&gt;Spectral Clustering&lt;/li&gt;
&lt;li&gt;Hierachical Clustering&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Other relevant algorithms

&lt;ul&gt;
&lt;li&gt;Expecatation Maximization&lt;/li&gt;
&lt;li&gt;Dimendsionality Reduction

&lt;ul&gt;
&lt;li&gt;Laplacian Eigenmap&lt;/li&gt;
&lt;li&gt;Locally Linear Embedding&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;computer-orgnisation&#34;&gt;Computer orgnisation&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Direct mapping

&lt;ul&gt;
&lt;li&gt;process is divided into pages&lt;/li&gt;
&lt;li&gt;main memory is divided into frames/blocks&lt;/li&gt;
&lt;li&gt;cache is divided into lines&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2017-12-05</title>
      <link>/post/til-2017-12-05/</link>
      <pubDate>Tue, 05 Dec 2017 00:38:00 +0000</pubDate>
      
      <guid>/post/til-2017-12-05/</guid>
      <description>

&lt;h2 id=&#34;paper-daily&#34;&gt;Paper Daily&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;(NIPS 2017) Visual Reference Resolution using Attention Memory for Visual Dialog, Paul Hongsuch Seo

&lt;ul&gt;
&lt;li&gt;An associative attention memory storing s sequence of previous (attention, key) pairs&lt;/li&gt;
&lt;li&gt;Retrieves the previous attention, taking into account recency, which is most relevant for the current Q&lt;/li&gt;
&lt;li&gt;Resoning ability, maybe the best single model (trained by mle) presently&lt;/li&gt;
&lt;li&gt;Other keywords, text as key, attention as value, aceess values according to key; Method is Attention over attention&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;computer-network-notes&#34;&gt;Computer Network Notes&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Classes (think in binary system)

&lt;ul&gt;
&lt;li&gt;CA: 1-126 ($2^{24}-2$)&lt;/li&gt;
&lt;li&gt;CB: 128-191 ($2^{16}-2$)&lt;/li&gt;
&lt;li&gt;CC: 192-223 ($2^8-2$)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;DBA: Directed Broadcast Address (NID, HID 1s [11.255.255.255])&lt;/li&gt;
&lt;li&gt;NID: (NID, HID 0s [11.0.0.0])&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;types-of-casting&#34;&gt;Types of casting&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Unicast&lt;/li&gt;
&lt;li&gt;Broadcast

&lt;ul&gt;
&lt;li&gt;Limited

&lt;ul&gt;
&lt;li&gt;11.0.0.0  |m|11.1.2.3 (Source Address)|255.255.255.255 (Destination Address)|&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Directed

&lt;ul&gt;
&lt;li&gt;11.0.0.0  |m|11.1.2.3|20.255.255.255|&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;subnets-subnet-mask-cidr&#34;&gt;Subnets, Subnet Mask, CIDR&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;subnetting disadvantage

&lt;ul&gt;
&lt;li&gt;reach the process complexly&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;The difference between in subnet and outside subnet;&lt;/li&gt;
&lt;li&gt;Every subnet waste two IP addresses for the NID and DBA

&lt;ul&gt;
&lt;li&gt;2 subnet: For CC: (128 - 2) x 2 = 252&lt;/li&gt;
&lt;li&gt;2 subnet: (200.1.2.0)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Subnet Mask: 32 bit

&lt;ul&gt;
&lt;li&gt;#1: #NID + #SID, #0: #HID&lt;/li&gt;
&lt;li&gt;can find out NID&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Variable lenght subnet masking (VLSM)&lt;/li&gt;
&lt;li&gt;Classless Inter Domain Routing

&lt;ul&gt;
&lt;li&gt;(a.b.c.d/n) n: #NID&lt;/li&gt;
&lt;li&gt;Rules of blocks

&lt;ul&gt;
&lt;li&gt;All IP addrees should be contiguous&lt;/li&gt;
&lt;li&gt;$2^n$&lt;/li&gt;
&lt;li&gt;Fast IP address in the block should be evenly divided by size of the block&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Subnetting in CIDR&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;operating-system-notes&#34;&gt;Operating System Notes&lt;/h2&gt;

&lt;h2 id=&#34;file-system&#34;&gt;File System&lt;/h2&gt;

&lt;h3 id=&#34;cache-memory&#34;&gt;cache memory&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Cache - Paging (main memory) - Secondary Memory

&lt;ul&gt;
&lt;li&gt;Hit latency: the time to hit in the cache&lt;/li&gt;
&lt;li&gt;Cache hit: a state in which data requested for processing by a component or application is found in the cache memory&lt;/li&gt;
&lt;li&gt;Cache miss: not found&lt;/li&gt;
&lt;li&gt;Miss latency: the time (in cycles) the CPU waits when a miss happen in the cache&lt;/li&gt;
&lt;li&gt;Page fault, Page hit&lt;/li&gt;
&lt;li&gt;Spatial/temporal locality&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Direct Mapping

&lt;ul&gt;
&lt;li&gt;[Tag | Index (line number)| (block) Offset]&lt;/li&gt;
&lt;li&gt;$2^m$ addresses&lt;/li&gt;
&lt;li&gt;$2^k$ cache entries&lt;/li&gt;
&lt;li&gt;$2^n$ block size&lt;/li&gt;
&lt;li&gt;Step:

&lt;ul&gt;
&lt;li&gt;Use the index part of the address to find the appropriate cache entry&lt;/li&gt;
&lt;li&gt;CHeck the tag to see if the entry contains the right data&lt;/li&gt;
&lt;li&gt;If it does, then use the offset to the find the correct byte&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>An introduction to Imitation Learning (Part 1)</title>
      <link>/post/imitation-learning-1/</link>
      <pubDate>Sun, 12 Mar 2017 22:38:00 +0000</pubDate>
      
      <guid>/post/imitation-learning-1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Knowledge arrangement about Reinforcement Learning</title>
      <link>/post/knowledge-arrangement-about-rl/</link>
      <pubDate>Wed, 20 Apr 2016 11:00:00 +0000</pubDate>
      
      <guid>/post/knowledge-arrangement-about-rl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The knowledge of domain name that everyone should know</title>
      <link>/post/knowledge-of-domain-name/</link>
      <pubDate>Mon, 11 Jan 2016 07:45:00 +0000</pubDate>
      
      <guid>/post/knowledge-of-domain-name/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The construction of user portrait based on Big Data (Theoretical section)</title>
      <link>/post/user-portrait-theoretical/</link>
      <pubDate>Sun, 10 Jan 2016 05:58:00 +0000</pubDate>
      
      <guid>/post/user-portrait-theoretical/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>

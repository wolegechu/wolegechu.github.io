<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yuchu Luo - 罗宇矗 on Yuchu Luo - 罗宇矗</title>
    <link>/</link>
    <description>Recent content in Yuchu Luo - 罗宇矗 on Yuchu Luo - 罗宇矗</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Yuchu Luo</copyright>
    <lastBuildDate>Fri, 02 Jun 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Virtual Memory Hardware</title>
      <link>/post/vm_hardware/</link>
      <pubDate>Tue, 26 Dec 2017 00:38:00 +0000</pubDate>
      
      <guid>/post/vm_hardware/</guid>
      <description>

&lt;h3 id=&#34;issues-in-sharing-physical-memory&#34;&gt;Issues in sharing physical memory&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/WX20171226-152306.png&#34; alt=&#34;&#34; /&gt;
- Protection
    - A bug in one process can corrupt in another
    - Must somehow prevent process A from trashing B&amp;rsquo;s memory
    - Also prevent A from even observing B&amp;rsquo;s memory (ssh-agent)
- Transparency
    - A process shouldn&amp;rsquo;t require particular physical memory bits
    - Yet processes often require large amounts of contiguous memory (for stack, large data structures, etc.)
- Resource exhaustion
    - Programmers typically assume machine has &amp;ldquo;enough&amp;rdquo; memory
    - Sum of sizes of all processes often greater than physical memory&lt;/p&gt;

&lt;h2 id=&#34;virtual-memory&#34;&gt;Virtual memory&lt;/h2&gt;

&lt;h3 id=&#34;goals&#34;&gt;goals&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Give each program its own &lt;em&gt;virtual&lt;/em&gt; address space

&lt;ul&gt;
&lt;li&gt;At runtime, &lt;strong&gt;Memory-Management Unit (MMU)&lt;/strong&gt; relocates each load/store&lt;/li&gt;
&lt;li&gt;Application doesn&amp;rsquo;t see physical memory addresses&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Also enforce protection

&lt;ul&gt;
&lt;li&gt;Prevent one app from messing with another&amp;rsquo;s memory&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;And allow programs to see more memory than exists

&lt;ul&gt;
&lt;li&gt;Somehow relocate some memory accesses to disk&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;virtual-memory-advantages&#34;&gt;Virtual memory advantages&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Can relocate program while running

&lt;ul&gt;
&lt;li&gt;Run partially in memory, partially on disk&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Most of a process&amp;rsquo;s memory may be idle (&lt;sup&gt;80&lt;/sup&gt;&amp;frasl;&lt;sub&gt;20&lt;/sub&gt; rule)

&lt;ul&gt;
&lt;li&gt;&lt;img src=&#34;/img/post/WX20171226-153927.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;Write idle parts to disk until needed&lt;/li&gt;
&lt;li&gt;Let other processes use memory of idle part&lt;/li&gt;
&lt;li&gt;Like CPU virtualization: when process not using CPU, switch (Not using amemory region? switch it to another process)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Challenge: VM = extra layer, could be slow&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ideas&#34;&gt;Ideas&lt;/h2&gt;

&lt;h3 id=&#34;ideal-1-load-time-linking&#34;&gt;Ideal 1: load-time linking&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/WX20171226-154928.png&#34; alt=&#34;&#34; /&gt;
- &lt;em&gt;Linker&lt;/em&gt; patches addresses of symbols like printf
- Idea: link when process executed, not at compile time
    - Determine where process will reside in memory
    - Adjust all refernces within program (using addtion)
- Problems?
    - How to enforce protection?
    - How to move once already in memory? (consider data pointers)
    - What if no contiguous free region fits program?&lt;/p&gt;

&lt;h3 id=&#34;ideal-2-base-bound-register&#34;&gt;Ideal 2: base + bound register&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/WX20171226-163437.png&#34; alt=&#34;&#34; /&gt;
- Two special privileged registers: &lt;strong&gt;base&lt;/strong&gt; snf &lt;strong&gt;bound&lt;/strong&gt;
- On each load/store/jump:
    - Physical address = virtual address + base
    - Check 0 ≤ vitual address ≤ bound, else trap to kernel
- How to move process in memory?
    - Change base register
- What happens on context switch?
    - OS must re-load base and bound register&lt;/p&gt;

&lt;h2 id=&#34;definition&#34;&gt;Definition&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Programs load/store to &lt;code&gt;virtual addresses&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Actual memory uses &lt;code&gt;physical addresses&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;VM Hardware is Memory Management Unit (&lt;code&gt;MMU&lt;/code&gt;)

&lt;ul&gt;
&lt;li&gt;Usually part of CPU&lt;/li&gt;
&lt;li&gt;Configured through privileged instructions (e.g., load bound reg)&lt;/li&gt;
&lt;li&gt;Translates from virtual to physical addresses&lt;/li&gt;
&lt;li&gt;Gives per-process view of memory called &lt;code&gt;address space&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;base-bound&#34;&gt;Base + bound&lt;/h2&gt;

&lt;h3 id=&#34;trade-offs&#34;&gt;Trade-offs&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Advantages

&lt;ul&gt;
&lt;li&gt;Cheap in terms of hardware: only two registers&lt;/li&gt;
&lt;li&gt;Cheap in terms of cycles: do add and compare in parallel&lt;/li&gt;
&lt;li&gt;Examples: Cray-1 used this scheme&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Disadvantages

&lt;ul&gt;
&lt;li&gt;Growing a process is expensive or impossible&lt;/li&gt;
&lt;li&gt;No way to share code or data (E.g., two copies of bochs, both running pintos)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;One solution: Multiple segments

&lt;ul&gt;
&lt;li&gt;E.g., separate code, stack, data segments&lt;/li&gt;
&lt;li&gt;Possibly multiple data segments&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;segmentation&#34;&gt;Segmentation&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/WX20171226-164915.png&#34; alt=&#34;&#34; /&gt;
- Let processes have many base/bound regs
    - Address space built from many segments
    - Can share/protect memory at segment granularity
- Must specify segment as part of virtual address&lt;/p&gt;

&lt;h3 id=&#34;segmentation-mechanics&#34;&gt;Segmentation mechanics&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/WX20171226-191449.png&#34; alt=&#34;&#34; /&gt;
- Each process has a segment table
- Each VA (Virtual Address) indicates a segment and offset:
    - Top bits of addr select segment, low bits select offset (PDP-10)
    - Or segment selected by instruction or operand (means you need wider &amp;ldquo;far&amp;rdquo; pointers to specify segment)&lt;/p&gt;

&lt;h3 id=&#34;segmentation-example&#34;&gt;Segmentation example&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;/img/post/WX20171226-192145.png&#34; alt=&#34;&#34; /&gt;
- 2-bit segment number (1st digit), 12 bit offset (last 3)
    - Where is 0x0&lt;/p&gt;

&lt;h3 id=&#34;trade-offs-1&#34;&gt;Trade-offs&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Advantages

&lt;ul&gt;
&lt;li&gt;Multiple segments per process&lt;/li&gt;
&lt;li&gt;Allows sharing!&lt;/li&gt;
&lt;li&gt;Don&amp;rsquo;t need entire process in memory&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Disadvantages

&lt;ul&gt;
&lt;li&gt;Requires translation hardware, which could limit performance&lt;/li&gt;
&lt;li&gt;Segments not completely transparent to program (e.g., default segment faster or uses shorter instruction)&lt;/li&gt;
&lt;li&gt;$n$ byte segment needs &lt;em&gt;n contiguous&lt;/em&gt; bytes of physical memory&lt;/li&gt;
&lt;li&gt;Makes &lt;em&gt;fragmentation&lt;/em&gt; a real problem&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;fragmentation&#34;&gt;Fragmentation&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Fragmentation =&amp;gt; Inability to use free memory&lt;/li&gt;
&lt;li&gt;Over time:

&lt;ul&gt;
&lt;li&gt;Variable-sized pices = many small holes (external fragmentation)&lt;/li&gt;
&lt;li&gt;Fixed-sized pieces = no external holes, but force internal waste (internal fragmentation)
&lt;img src=&#34;/img/post/WX20171226-213655.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;alternatives-to-hardware-mmu&#34;&gt;Alternatives to hardware MMU&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Language-level protection (Java)

&lt;ul&gt;
&lt;li&gt;Single address space for different modules&lt;/li&gt;
&lt;li&gt;Language enforces isolation&lt;/li&gt;
&lt;li&gt;Singularity OS does this&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Software fault isolation

&lt;ul&gt;
&lt;li&gt;Instrument compiler output&lt;/li&gt;
&lt;li&gt;Checks before ever ystore operation prevents modules from trashing each other&lt;/li&gt;
&lt;li&gt;Google Native Client does this&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;paging&#34;&gt;Paging&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Divede memory up into small &lt;em&gt;pages&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Map virtual pages to physical pages

&lt;ul&gt;
&lt;li&gt;Each process has separate mapping&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Allow OS to gain control on certain operation

&lt;ul&gt;
&lt;li&gt;Read-only pages trap to OS on write&lt;/li&gt;
&lt;li&gt;Invalid pages trap to OS on read or write&lt;/li&gt;
&lt;li&gt;OS can change mapping and resume application&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Other features sometimes found:

&lt;ul&gt;
&lt;li&gt;Hardware can set &amp;ldquo;accessed&amp;rdquo; and &amp;ldquo;dirty&amp;rdquo; bits&lt;/li&gt;
&lt;li&gt;Control page execute permission separately from read/write&lt;/li&gt;
&lt;li&gt;Control caching or memory consistency of page&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;trade-offs-2&#34;&gt;Trade-offs&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Eliminates external fragmentation&lt;/li&gt;
&lt;li&gt;Simplifies allocation, free, and backing storage (swap)&lt;/li&gt;
&lt;li&gt;Average internal fragmentation of .5 pages per &amp;ldquo;segment&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;simplified-allocation&#34;&gt;Simplified allocation&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Allocate any physical page to any process&lt;/li&gt;
&lt;li&gt;Can store idle virtual pages on disk&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;paging-data-structures&#34;&gt;Paging data structures&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Pages are fixed size, e.g., 4K

&lt;ul&gt;
&lt;li&gt;Least significant 12 ($log_{2}4K$) bits of address are page offset&lt;/li&gt;
&lt;li&gt;Most significant bits are &lt;em&gt;page number&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Each process has a page table

&lt;ul&gt;
&lt;li&gt;Maps &lt;em&gt;virtual page numbers (VPNs)&lt;/em&gt; to &lt;em&gt;physical page numbers (PPNS)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Also includes bits for protection, validity, etc.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;On memory access: Translate VPN to PPN, then add offset
&lt;img src=&#34;/img/post/WX20171227-094654.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;###Example: Paging on PDP-11
- 64K virtual memory, 8K pages
    - Separate address space for instructions &amp;amp; data
    - I.e., can&amp;rsquo;t read your own instructions with a load
- Entire page table stored in registers
    - 8 Instruction page translation
    - 8 Data page translation
- Swap 16 machine registers on each context switch&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2017-12-12</title>
      <link>/post/til-2017-12-12/</link>
      <pubDate>Tue, 12 Dec 2017 00:38:00 +0000</pubDate>
      
      <guid>/post/til-2017-12-12/</guid>
      <description>

&lt;h2 id=&#34;note-deep-learning-practice-and-trends-nips-2017&#34;&gt;[Note] Deep Learning: Practice and Trends (NIPS 2017)&lt;/h2&gt;

&lt;h3 id=&#34;practice&#34;&gt;Practice&lt;/h3&gt;

&lt;h4 id=&#34;architectures&#34;&gt;Architectures&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Convolutional Nets

&lt;ul&gt;
&lt;li&gt;Locality: objects tend to have a local spatial support

&lt;ul&gt;
&lt;li&gt;locally-connected&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Teanslation invariance: object appearance is independent of location&lt;/li&gt;
&lt;li&gt;Tricks of the Trade

&lt;ul&gt;
&lt;li&gt;Optimization

&lt;ul&gt;
&lt;li&gt;SGD with momentum&lt;/li&gt;
&lt;li&gt;Batch Norm&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Initialization

&lt;ul&gt;
&lt;li&gt;Weight init: start from the weights which lead to stable training&lt;/li&gt;
&lt;li&gt;Sample from zero-mean normal distribution w/ small variance 0.01

&lt;ul&gt;
&lt;li&gt;Adaptively choose variance for each layer

&lt;ul&gt;
&lt;li&gt;preserve gradient magnitude: 1/sqrt(fan_in)&lt;/li&gt;
&lt;li&gt;works fine for VGGNets (up to 20 layers), but not sufficient for deeper nets&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Model

&lt;ul&gt;
&lt;li&gt;Stacking 3x3 convolutions&lt;/li&gt;
&lt;li&gt;Inception&lt;/li&gt;
&lt;li&gt;ResNet adds modules which ensure that the gradient doesn&amp;rsquo;t vanish&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;recurrent-nets&#34;&gt;Recurrent Nets&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Two Key Ingredients: Neural Embeddings, Recurrent Language Models&lt;/li&gt;
&lt;li&gt;Dot product Attention

&lt;ul&gt;
&lt;li&gt;Inputs: &amp;ldquo;I am a cat&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Input RNN states: $e_1e_2e_3e_4$&lt;/li&gt;
&lt;li&gt;Decoder RNN state at step i (query): $h_i$&lt;/li&gt;
&lt;li&gt;Compute scalars $h_i^Te_1, h_i^Te_2,&amp;hellip;$representing similarity / relevance between encoder steps and query&lt;/li&gt;
&lt;li&gt;Normaliza [h_i^Te_1,h_i^Te_2,&amp;hellip;] with softmax to produce attention weights&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Tricks of the Trade

&lt;ul&gt;
&lt;li&gt;Long sequences?

&lt;ul&gt;
&lt;li&gt;Attention&lt;/li&gt;
&lt;li&gt;Bigger state&lt;/li&gt;
&lt;li&gt;Reverse inputs&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Can&amp;rsquo;t overfit?

&lt;ul&gt;
&lt;li&gt;Bigger hidden state&lt;/li&gt;
&lt;li&gt;Deep LSTM + Skip Connections&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Overfit?

&lt;ul&gt;
&lt;li&gt;Dropout + Ensembles&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Tuning

&lt;ul&gt;
&lt;li&gt;Keep calm and decrease your learning rate&lt;/li&gt;
&lt;li&gt;Initalization of parameters is critical (in seq2seq we used U(-0.05, 0.05))&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clip the gradients!&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;E.g. if ||grad|| &amp;gt; 5: grad = grad/||grad|| * 5&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Attention and Memory Toolbox

&lt;ul&gt;
&lt;li&gt;Read/Write memories (neural turing machine)&lt;/li&gt;
&lt;li&gt;Sequence Prediction&lt;/li&gt;
&lt;li&gt;Seq2Seq&lt;/li&gt;
&lt;li&gt;Temporal Hierarchies&lt;/li&gt;
&lt;li&gt;Multimodality&lt;/li&gt;
&lt;li&gt;Attention/Pointers&lt;/li&gt;
&lt;li&gt;Recurrent Architectures&lt;/li&gt;
&lt;li&gt;Key, Value memories&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;trends&#34;&gt;Trends&lt;/h3&gt;

&lt;h4 id=&#34;autoregressive-models&#34;&gt;Autoregressive Models&lt;/h4&gt;

&lt;p&gt;$$P(x;\theta) = \prod_{n=1}^N P(x&lt;em&gt;n|x&lt;/em&gt;{&lt;n&gt;};\theta)$$
- Each factor can be parametrized by $\theta$, which can be shared
- The variables can be arbitrarily ordered and grouped, as long as the ordering and grouping is consistent.
- Building Blocks
    - Inputs and Outpus: these can also be conditioning variables
        - Image pixels
        - Text sequences
        - Audio waveforms
    - Architectures
        - Recurrent, over space and time
        - Causal convolutions
        - Causal conv + attention
        - Attention-only!
    - Losses:
        - Discrete case: softmax cross entropy
        - Continuous: Gaussian (mixture) likelihood
        - &lt;strong&gt;Mixture of logistics loss&lt;/strong&gt; (PixelCNN++ in ICLR 2017)
            - $$ v ~ \sum_{i=1}^K \pi_i logistic(\mu_i,s&lt;em&gt;i) $$
            - $$ P(x|\pi,\mu,s) = \sum&lt;/em&gt;{i=1}^K \pi_i[\sigma((x+0.5-\mu_i)/s_i) - \sigma((x-0.5-\mu_i) / s_i)] $$
- Autogressive scoring and sampling
    - Fully sequential models:
        - PixelCNN, PixelCNN++, WaveNet, &amp;hellip;
        - O(1) scoring, O(N) sampling
    - Models with conditional independence assumptions:
        - O(1) scoring, sampling can be O(1), O(log N), etc depending on cond. indep. assumptions
    - Distilled models:
        - Parall WaveNet, Parallel NMT
        - O(N) scoring, O(1) sampling&lt;/p&gt;

&lt;h4 id=&#34;domain-alignment-unsupervised&#34;&gt;Domain Alignment (unsupervised)&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Building Blocks

&lt;ul&gt;
&lt;li&gt;Inputs and Outpus

&lt;ul&gt;
&lt;li&gt;Sets of images with shared structure, but weak or no alignment&lt;/li&gt;
&lt;li&gt;Text corpora in different languages, but not parallel&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Architecures

&lt;ul&gt;
&lt;li&gt;Nothing fancy!&lt;/li&gt;
&lt;li&gt;For images: mostly convolutional nets&lt;/li&gt;
&lt;li&gt;For text: recurrent&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Losses

&lt;ul&gt;
&lt;li&gt;Latent space: Domain confusion&lt;/li&gt;
&lt;li&gt;Pixel space: Cycle consistency&lt;/li&gt;
&lt;li&gt;Both adversarial loss and likelihoods work!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Approach

&lt;ul&gt;
&lt;li&gt;Cross-modal retrieval&lt;/li&gt;
&lt;li&gt;Unsupervised domain transfer for classification&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Case&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;DiscoGAN - Car2Face&lt;/li&gt;
&lt;li&gt;GraspGAN&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Unsupervised Neural Machine Translation&lt;/p&gt;

&lt;h4 id=&#34;learning-to-learn-meta-learning&#34;&gt;Learning to Learn / Meta Learning&lt;/h4&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Building Blocks:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Inputs and Outputs: text, images, actions&lt;/li&gt;
&lt;li&gt;Architectures: Recurrent, CNN (+attention)&lt;/li&gt;
&lt;li&gt;Losses (loss based on another loss): Model, Optimization, Initialization&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Learning to learn:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What is Meta Learning?

&lt;ul&gt;
&lt;li&gt;Go beyond train/test from same distribution&lt;/li&gt;
&lt;li&gt;Task between train/test changes, so model has to &amp;ldquo;learn to learn&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Model Based, Metric Based, Optimization Based&lt;/p&gt;

&lt;h2 id=&#34;conclusions-and-expectations&#34;&gt;Conclusions and Expectations&lt;/h2&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Deep autoregressive models and ConvNets are ubiquitous and already useful in consumer applications&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Inductive biases are useful&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;spatial invariance for CNNs&lt;/li&gt;
&lt;li&gt;time recurrence for RNNs&lt;/li&gt;
&lt;li&gt;Permutation invariance for Graphs&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Simple tricks like ResNet will be discovered&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Adversarial networks and unsupervised domain adaptation have interesting market app (e.g. phone apps like style transfer)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Meta learning: more and more of the model lifecycle (train/val/test) will be learned in an end-to-end way&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Program syntesis + Graph networks may be very important and find more real-world applications (e.g. RobustFill)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2017-12-08</title>
      <link>/post/til-2017-12-08/</link>
      <pubDate>Fri, 08 Dec 2017 00:38:00 +0000</pubDate>
      
      <guid>/post/til-2017-12-08/</guid>
      <description>

&lt;h2 id=&#34;paper-daily&#34;&gt;Paper Daily&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Where Classification Fails, Interpretation Rises

&lt;ul&gt;
&lt;li&gt;apply an attention mechanism to the adversarial examples detection&lt;/li&gt;
&lt;li&gt;uisng attention to defend against adversarial examples&lt;/li&gt;
&lt;li&gt;(this paper is hard to read)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Deep Image Prior

&lt;ul&gt;
&lt;li&gt;randomly-initialized neural network can be used as a handcrafted prior with excellent results&lt;/li&gt;
&lt;li&gt;search in parameter space&lt;/li&gt;
&lt;li&gt;apply untrianed CNN, fit a G network to a single degraded image.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Deep Reinforcement Learning framework for Autonoumous Driving

&lt;ul&gt;
&lt;li&gt;Deep Deterministic Actor Critic (DDAC)

&lt;ul&gt;
&lt;li&gt;actor: provides the policy mapping from a state to action&lt;/li&gt;
&lt;li&gt;critic: evaluates the value of the action taken (same as Q-function)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;review-of-clustering-algorithms&#34;&gt;Review of clustering algorithms&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Clustering

&lt;ul&gt;
&lt;li&gt;k-means&lt;/li&gt;
&lt;li&gt;k-medoids&lt;/li&gt;
&lt;li&gt;Gaussian Mixture Model&lt;/li&gt;
&lt;li&gt;Spectral Clustering&lt;/li&gt;
&lt;li&gt;Hierachical Clustering&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Other relevant algorithms

&lt;ul&gt;
&lt;li&gt;Expecatation Maximization&lt;/li&gt;
&lt;li&gt;Dimendsionality Reduction

&lt;ul&gt;
&lt;li&gt;Laplacian Eigenmap&lt;/li&gt;
&lt;li&gt;Locally Linear Embedding&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;computer-orgnisation&#34;&gt;Computer orgnisation&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Direct mapping

&lt;ul&gt;
&lt;li&gt;process is divided into pages&lt;/li&gt;
&lt;li&gt;main memory is divided into frames/blocks&lt;/li&gt;
&lt;li&gt;cache is divided into lines&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2017-12-05</title>
      <link>/post/til-2017-12-05/</link>
      <pubDate>Tue, 05 Dec 2017 00:38:00 +0000</pubDate>
      
      <guid>/post/til-2017-12-05/</guid>
      <description>

&lt;h2 id=&#34;paper-daily&#34;&gt;Paper Daily&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;(NIPS 2017) Visual Reference Resolution using Attention Memory for Visual Dialog, Paul Hongsuch Seo

&lt;ul&gt;
&lt;li&gt;An associative attention memory storing s sequence of previous (attention, key) pairs&lt;/li&gt;
&lt;li&gt;Retrieves the previous attention, taking into account recency, which is most relevant for the current Q&lt;/li&gt;
&lt;li&gt;Resoning ability, maybe the best single model (trained by mle) presently&lt;/li&gt;
&lt;li&gt;Other keywords, text as key, attention as value, aceess values according to key; Method is Attention over attention&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;computer-network-notes&#34;&gt;Computer Network Notes&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Classes (think in binary system)

&lt;ul&gt;
&lt;li&gt;CA: 1-126 ($2^{24}-2$)&lt;/li&gt;
&lt;li&gt;CB: 128-191 ($2^{16}-2$)&lt;/li&gt;
&lt;li&gt;CC: 192-223 ($2^8-2$)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;DBA: Directed Broadcast Address (NID, HID 1s [11.255.255.255])&lt;/li&gt;
&lt;li&gt;NID: (NID, HID 0s [11.0.0.0])&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;types-of-casting&#34;&gt;Types of casting&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Unicast&lt;/li&gt;
&lt;li&gt;Broadcast

&lt;ul&gt;
&lt;li&gt;Limited

&lt;ul&gt;
&lt;li&gt;11.0.0.0  |m|11.1.2.3 (Source Address)|255.255.255.255 (Destination Address)|&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Directed

&lt;ul&gt;
&lt;li&gt;11.0.0.0  |m|11.1.2.3|20.255.255.255|&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;subnets-subnet-mask-cidr&#34;&gt;Subnets, Subnet Mask, CIDR&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;subnetting disadvantage

&lt;ul&gt;
&lt;li&gt;reach the process complexly&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;The difference between in subnet and outside subnet;&lt;/li&gt;
&lt;li&gt;Every subnet waste two IP addresses for the NID and DBA

&lt;ul&gt;
&lt;li&gt;2 subnet: For CC: (128 - 2) x 2 = 252&lt;/li&gt;
&lt;li&gt;2 subnet: (200.1.2.0)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Subnet Mask: 32 bit

&lt;ul&gt;
&lt;li&gt;#1: #NID + #SID, #0: #HID&lt;/li&gt;
&lt;li&gt;can find out NID&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Variable lenght subnet masking (VLSM)&lt;/li&gt;
&lt;li&gt;Classless Inter Domain Routing

&lt;ul&gt;
&lt;li&gt;(a.b.c.d/n) n: #NID&lt;/li&gt;
&lt;li&gt;Rules of blocks

&lt;ul&gt;
&lt;li&gt;All IP addrees should be contiguous&lt;/li&gt;
&lt;li&gt;$2^n$&lt;/li&gt;
&lt;li&gt;Fast IP address in the block should be evenly divided by size of the block&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Subnetting in CIDR&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;operating-system-notes&#34;&gt;Operating System Notes&lt;/h2&gt;

&lt;h2 id=&#34;file-system&#34;&gt;File System&lt;/h2&gt;

&lt;h3 id=&#34;cache-memory&#34;&gt;cache memory&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Cache - Paging (main memory) - Secondary Memory

&lt;ul&gt;
&lt;li&gt;Hit latency: the time to hit in the cache&lt;/li&gt;
&lt;li&gt;Cache hit: a state in which data requested for processing by a component or application is found in the cache memory&lt;/li&gt;
&lt;li&gt;Cache miss: not found&lt;/li&gt;
&lt;li&gt;Miss latency: the time (in cycles) the CPU waits when a miss happen in the cache&lt;/li&gt;
&lt;li&gt;Page fault, Page hit&lt;/li&gt;
&lt;li&gt;Spatial/temporal locality&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Direct Mapping

&lt;ul&gt;
&lt;li&gt;[Tag | Index (line number)| (block) Offset]&lt;/li&gt;
&lt;li&gt;$2^m$ addresses&lt;/li&gt;
&lt;li&gt;$2^k$ cache entries&lt;/li&gt;
&lt;li&gt;$2^n$ block size&lt;/li&gt;
&lt;li&gt;Step:

&lt;ul&gt;
&lt;li&gt;Use the index part of the address to find the appropriate cache entry&lt;/li&gt;
&lt;li&gt;CHeck the tag to see if the entry contains the right data&lt;/li&gt;
&lt;li&gt;If it does, then use the offset to the find the correct byte&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>End-to-end Deep Models For Self-driving Car (Avaliable soon)</title>
      <link>/talk/end-to-end-deep-models-for-self-driving-car/</link>
      <pubDate>Sun, 26 Nov 2017 19:00:00 +0000</pubDate>
      
      <guid>/talk/end-to-end-deep-models-for-self-driving-car/</guid>
      <description>

&lt;hr /&gt;

&lt;h2 id=&#34;reference&#34;&gt;Reference:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Huval, Brody, et al. &amp;ldquo;An empirical evaluation of deep learning on highway driving.&amp;ldquo; arXiv preprint arXiv:1504.01716 (2015).&lt;/li&gt;
&lt;li&gt;Ulbrich, Simon, et al. &amp;ldquo;Towards a Functional System Architecture for Automated Vehicles.&amp;ldquo; arXiv preprint arXiv:1703.08557 (2017).&lt;/li&gt;
&lt;li&gt;Pomerleau, Dean A. &amp;ldquo;Alvinn: An autonomous land vehicle in a neural network.&amp;ldquo; 
Advances in neural information processing systems. 1989.&lt;/li&gt;
&lt;li&gt;Muller, Urs, et al. &amp;ldquo;Off-road obstacle avoidance through end-to-end learning.“ Advances in neural information processing systems. 2006.APA&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Chen, Chenyi, et al. &amp;ldquo;Deepdriving: Learning affordance for direct perception in autonomous driving.&amp;ldquo; Proceedings of the IEEE International Conference on Computer Vision. 2015.&lt;/li&gt;
&lt;li&gt;Chen, Chenyi, et al. &amp;ldquo;Deepdriving: Learning affordance for direct perception in autonomous driving.&amp;ldquo; Proceedings of the IEEE International Conference on Computer Vision. 2015.&lt;/li&gt;
&lt;li&gt;Bojarski, Mariusz, et al. &amp;ldquo;End to end learning for self-driving cars.&amp;ldquo; arXiv preprint arXiv:1604.07316 (2016).&lt;/li&gt;
&lt;li&gt;Codevilla, Felipe, et al. &amp;ldquo;End-to-end driving via conditional imitation learning.&amp;ldquo; arXiv preprint arXiv:1710.02410 (2017).&lt;/li&gt;
&lt;li&gt;Xu, Huazhe, et al. &amp;ldquo;End-to-end learning of driving models from large-scale video datasets.&amp;ldquo; arXiv preprint arXiv:1612.01079(2016).&lt;/li&gt;
&lt;li&gt;Mukadam, Mustafa, et al. “Tactical Decision Making for Lane Changing with Deep Reinforcement Learning.&amp;rdquo; (2017).&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>卷积神经网络：从相遇相知到相爱</title>
      <link>/talk/cnn/</link>
      <pubDate>Fri, 10 Nov 2017 19:00:00 +0000</pubDate>
      
      <guid>/talk/cnn/</guid>
      <description>&lt;hr /&gt;

&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;7aba17f26f474cb9aebb0ffba3c11446&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>如何实现无人驾驶</title>
      <link>/talk/how-to-build-self-driving-car/</link>
      <pubDate>Fri, 20 Oct 2017 19:00:00 +0000</pubDate>
      
      <guid>/talk/how-to-build-self-driving-car/</guid>
      <description>&lt;p&gt;MIL 智能体组无人驾驶汽车项目介绍&lt;/p&gt;

&lt;hr /&gt;
</description>
    </item>
    
    <item>
      <title>Deep Reinforcement Learning</title>
      <link>/talk/deep-reinforcemnt-learning/</link>
      <pubDate>Mon, 28 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/talk/deep-reinforcemnt-learning/</guid>
      <description>&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;62b49c13db9b4b61a97bc64140d96453&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;Markov Decision Processes&lt;/li&gt;
&lt;li&gt;Policy Learning and Value Learning&lt;/li&gt;
&lt;li&gt;Bellman Equation&lt;/li&gt;
&lt;li&gt;Model-based and Model-free&lt;/li&gt;
&lt;li&gt;Q-learning, Policy Gradients, Actor-Critic&lt;/li&gt;
&lt;li&gt;Experience Replay&lt;/li&gt;
&lt;li&gt;Applications: Atari Game, Recurrent Attention Model(RAM)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Referfence and Recommend Materials&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CS231n: Deep Reinforcement Learning (&lt;a href=&#34;https://www.youtube.com/watch?v=lvoHnicueoE&amp;amp;index=14&amp;amp;list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&#34; target=&#34;_blank&#34;&gt;Video&lt;/a&gt;) (&lt;a href=&#34;http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture14.pdf&#34; target=&#34;_blank&#34;&gt;Slide&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1312.5602&#34; target=&#34;_blank&#34;&gt;Playing Atari with Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1406.6247&#34; target=&#34;_blank&#34;&gt;Recurrent Models of Visual Attention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow&#34; target=&#34;_blank&#34;&gt;Reinforcement Learning Methods and Tutorials&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Intro to Reinforcement Learning</title>
      <link>/talk/reinforcement-learning/</link>
      <pubDate>Wed, 23 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/talk/reinforcement-learning/</guid>
      <description>&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;2b0ad1af004f4266b693269e394f35cf&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;Markov Decision Processes&lt;/li&gt;
&lt;li&gt;Model-based and Model-free&lt;/li&gt;
&lt;li&gt;Value Iteration and Policy Iteration&lt;/li&gt;
&lt;li&gt;Q-learning and approximate Q-learning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Referfence and Recommend Materials&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25319023&#34; target=&#34;_blank&#34;&gt;强化学习（Reinforcement Learning）知识整理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;UC Berkeley CS188 Intro to AI&#34; target=&#34;_blank&#34;&gt;UC Berkeley CS188 Intro to AI&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Markov Decision Processe

&lt;ul&gt;
&lt;li&gt;(&lt;a href=&#34;http://www.youtube.com/watch?v=Oxqwwnm_x0s&#34; target=&#34;_blank&#34;&gt;lecture I&lt;/a&gt;) (&lt;a href=&#34;http://www.youtube.com/watch?v=6pBvbLyn6fE&#34; target=&#34;_blank&#34;&gt;lecture II&lt;/a&gt;) (&lt;a href=&#34;http://ai.berkeley.edu/slides/Lecture%208%20--%20MDPs%20I/SP14%20CS188%20Lecture%208%20--%20MDPs%20I.pptx&#34; target=&#34;_blank&#34;&gt;PPT I&lt;/a&gt;) (&lt;a href=&#34;http://ai.berkeley.edu/slides/Lecture%209%20--%20MDPs%20II/SP14%20CS188%20Lecture%209%20--%20MDPs%20II.pptx&#34; target=&#34;_blank&#34;&gt;PPT II&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Reinforcement Learning

&lt;ul&gt;
&lt;li&gt;(&lt;a href=&#34;http://www.youtube.com/watch?v=IXuHxkpO5E8&#34; target=&#34;_blank&#34;&gt;lecture I&lt;/a&gt;) (&lt;a href=&#34;http://www.youtube.com/watch?v=yNeSFbE1jdY&#34; target=&#34;_blank&#34;&gt;lecture II&lt;/a&gt;) (&lt;a href=&#34;http://ai.berkeley.edu/slides/Lecture%2010%20--%20Reinforcement%20Learning%20I/SP14%20CS188%20Lecture%2010%20--%20Reinforcement%20Learning%20I.pptx&#34; target=&#34;_blank&#34;&gt;PPT I&lt;/a&gt;) (&lt;a href=&#34;http://ai.berkeley.edu/slides/Lecture%2011%20--%20Reinforcement%20Learning%20II/SP14%20CS188%20Lecture%2011%20--%20Reinforcement%20Learning%20II.pptx&#34; target=&#34;_blank&#34;&gt;PPT II&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>An Quadrotor Safety Monitorting System</title>
      <link>/project/an-quadrotor-safety-monitorting-system/</link>
      <pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/project/an-quadrotor-safety-monitorting-system/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Implemented and optimized a anomaly detection algorithm called Isolation Forest, which can receive temporal information and feed back the abnormal degree.&lt;/li&gt;
&lt;li&gt;Developed an exploration tool for the iForest algorithm, which can do visualization to a certain extent&lt;/li&gt;
&lt;li&gt;Won Provincial 1st Prizes both in the 2017 Challenge Cup and the E-Commerce Competition, Technical group. And get the qualification to the 2017 national contests.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Predicting Rossmann Store Sales</title>
      <link>/project/rossmann/</link>
      <pubDate>Sun, 19 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/project/rossmann/</guid>
      <description>&lt;p&gt;Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied.&lt;/p&gt;

&lt;p&gt;In their first Kaggle competition, Rossmann is challenging you to predict 6 weeks of daily sales for 1,115 stores located across Germany. Reliable sales forecasts enable store managers to create effective staff schedules that increase productivity and motivation. By helping Rossmann create a robust prediction model, you will help store managers stay focused on what’s most important to them: their customers and their teams!&lt;/p&gt;

&lt;p&gt;(There are a lot of flaws due to lack of time.)
You can see the report &lt;a href=&#34;https://github.com/wolegechu/Machine_Learning_Nanodegree/tree/master/Capstone&#34; target=&#34;_blank&#34;&gt;there&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Digit Recognition Program</title>
      <link>/project/digit_recognition/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/project/digit_recognition/</guid>
      <description>&lt;p&gt;In this project, I used deep neural networks and convolutional neural networks to create a program that prints numbers it observes in real time from images it is given. First, I designed and tested a model architecture that can identify sequences of digits in an image. Next, I trained that model so it could decode sequences of digits from natural images by using the Street View House Numbers (SVHN) dataset. After the model was properly trained, I then tested my model using a program on newly-captured images. Finally, I refined your implementation to also localize where numbers are on the image, and test this localization on newly-captured images.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The main techniques used:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Deep Neural Networks&lt;/li&gt;
&lt;li&gt;Convolutional Neural Networks&lt;/li&gt;
&lt;li&gt;Adadelta&lt;/li&gt;
&lt;li&gt;Keras based on TensorFlow&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can see the code(iPython notebook) &lt;a href=&#34;https://github.com/wolegechu/Machine_Learning_Nanodegree/blob/master/5.%20Digit%20Recognition/digit_recognition.ipynb&#34; target=&#34;_blank&#34;&gt;there&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Train a Smartcab How to Drive</title>
      <link>/project/smartcab/</link>
      <pubDate>Tue, 14 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/project/smartcab/</guid>
      <description>

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;p&gt;In this project I applied reinforcement learning techniques for a self-driving agent in a simplified world to aid it in effectively reaching its destinations in the allotted time. I first investigated the environment the agent operates in by constructing a very basic driving implementation. Once the agent is successful at operating within the environment, I then identified each possible state the agent can be in when considering such things as traffic lights and oncoming traffic at each intersection. With states identified, I then implemented a Q-Learning algorithm for the self-driving agent to guide the agent towards its destination within the allotted time. Finally, I improved upon the Q-Learning algorithm to find the best configuration of learning and exploration factors to ensure the self-driving agent is reaching its destinations with consistently positive results.&lt;/p&gt;

&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;

&lt;p&gt;In the not-so-distant future, taxicab companies across the United States no longer employ human drivers to operate their fleet of vehicles. Instead, the taxicabs are operated by self-driving agents, known as &lt;em&gt;smartcabs&lt;/em&gt;, to transport people from one location to another within the cities those companies operate. In major metropolitan areas, such as Chicago, New York City, and San Francisco, an increasing number of people have come to depend on &lt;em&gt;smartcabs&lt;/em&gt; to get to where they need to go as safely and reliably as possible. Although &lt;em&gt;smartcabs&lt;/em&gt; have become the transport of choice, concerns have arose that a self-driving agent might not be as safe or reliable as human drivers, particularly when considering city traffic lights and other vehicles. To alleviate these concerns, my task is to use reinforcement learning techniques to construct a demonstration of a &lt;em&gt;smartcab&lt;/em&gt; operating in real-time to prove that both safety and reliability can be achieved.&lt;/p&gt;

&lt;h3 id=&#34;below-is-the-final-score&#34;&gt;Below is the final score:&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;/img/posters/smartcab.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-main-techniques-used&#34;&gt;The main techniques used:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Markov Decision Processes&lt;/li&gt;
&lt;li&gt;Reinforcement Learning&lt;/li&gt;
&lt;li&gt;Game Theory&lt;/li&gt;
&lt;li&gt;More Game Theory beginning at Stochastic games and Multi-agent RL&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can see the code(iPython notebook) &lt;a href=&#34;https://github.com/wolegechu/Machine_Learning_Nanodegree/blob/master/4.%20Smartcab/smartcab.ipynb&#34; target=&#34;_blank&#34;&gt;there&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An introduction to Imitation Learning (Part 1)</title>
      <link>/post/imitation-learning-1/</link>
      <pubDate>Sun, 12 Mar 2017 22:38:00 +0000</pubDate>
      
      <guid>/post/imitation-learning-1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Creating Customer Segments</title>
      <link>/project/customer-segments/</link>
      <pubDate>Sun, 12 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/project/customer-segments/</guid>
      <description>&lt;p&gt;In this project I applied unsupervised learning techniques on product spending data collected for customers of a wholesale distributor in Lisbon, Portugal to identify customer segments hidden in the data. I first explored the data by selecting a small subset to sample and determine if any product categories highly correlate with one another. Afterwards, I preprocessed the data by scaling each product category and then identifying (and removing) unwanted outliers. With the good, clean customer spending data, I applied PCA transformations to the data and implement clustering algorithms to segment the transformed customer data. Finally, I compared the segmentation found with an additional labeling and consider ways this information could assist the wholesale distributor with future service changes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The main techniques used:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Clustering&lt;/li&gt;
&lt;li&gt;More Clustering&lt;/li&gt;
&lt;li&gt;Feature Scaling&lt;/li&gt;
&lt;li&gt;Feature Selection&lt;/li&gt;
&lt;li&gt;PCA&lt;/li&gt;
&lt;li&gt;Feature Transformation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can see the code(iPython notebook) &lt;a href=&#34;https://github.com/wolegechu/Machine_Learning_Nanodegree/blob/master/3.%20Customer%20Segments/customer_segments.ipynb&#34; target=&#34;_blank&#34;&gt;there&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
